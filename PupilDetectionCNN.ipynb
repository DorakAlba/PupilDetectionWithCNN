{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhGsXE0GtKD6",
        "outputId": "9aa7e8d8-0ba9-4ce8-ebb7-081e19823616"
      },
      "source": [
        "!unzip CASIA1.zip\n",
        "!pip install --upgrade albumentations\n",
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  CASIA1.zip\n",
            "   creating: CASIA1/1/\n",
            "  inflating: CASIA1/1/001_1_1.jpg    \n",
            "  inflating: CASIA1/1/001_1_2.jpg    \n",
            "  inflating: CASIA1/1/001_1_3.jpg    \n",
            " extracting: CASIA1/1/001_2_1.jpg    \n",
            "  inflating: CASIA1/1/001_2_2.jpg    \n",
            "  inflating: CASIA1/1/001_2_3.jpg    \n",
            "  inflating: CASIA1/1/001_2_4.jpg    \n",
            "   creating: CASIA1/10/\n",
            "  inflating: CASIA1/10/010_1_1.jpg   \n",
            "  inflating: CASIA1/10/010_1_2.jpg   \n",
            "  inflating: CASIA1/10/010_1_3.jpg   \n",
            "  inflating: CASIA1/10/010_2_1.jpg   \n",
            "  inflating: CASIA1/10/010_2_2.jpg   \n",
            "  inflating: CASIA1/10/010_2_3.jpg   \n",
            "  inflating: CASIA1/10/010_2_4.jpg   \n",
            "   creating: CASIA1/100/\n",
            "  inflating: CASIA1/100/100_1_1.jpg  \n",
            "  inflating: CASIA1/100/100_1_2.jpg  \n",
            "  inflating: CASIA1/100/100_1_3.jpg  \n",
            "  inflating: CASIA1/100/100_2_1.jpg  \n",
            " extracting: CASIA1/100/100_2_2.jpg  \n",
            " extracting: CASIA1/100/100_2_3.jpg  \n",
            "  inflating: CASIA1/100/100_2_4.jpg  \n",
            "   creating: CASIA1/101/\n",
            "  inflating: CASIA1/101/101_1_1.jpg  \n",
            "  inflating: CASIA1/101/101_1_2.jpg  \n",
            "  inflating: CASIA1/101/101_1_3.jpg  \n",
            "  inflating: CASIA1/101/101_2_1.jpg  \n",
            "  inflating: CASIA1/101/101_2_2.jpg  \n",
            "  inflating: CASIA1/101/101_2_3.jpg  \n",
            "  inflating: CASIA1/101/101_2_4.jpg  \n",
            "   creating: CASIA1/102/\n",
            "  inflating: CASIA1/102/102_1_1.jpg  \n",
            "  inflating: CASIA1/102/102_1_2.jpg  \n",
            "  inflating: CASIA1/102/102_1_3.jpg  \n",
            " extracting: CASIA1/102/102_2_1.jpg  \n",
            "  inflating: CASIA1/102/102_2_2.jpg  \n",
            "  inflating: CASIA1/102/102_2_3.jpg  \n",
            "  inflating: CASIA1/102/102_2_4.jpg  \n",
            "   creating: CASIA1/103/\n",
            "  inflating: CASIA1/103/103_1_1.jpg  \n",
            "  inflating: CASIA1/103/103_1_2.jpg  \n",
            "  inflating: CASIA1/103/103_1_3.jpg  \n",
            "  inflating: CASIA1/103/103_2_1.jpg  \n",
            "  inflating: CASIA1/103/103_2_2.jpg  \n",
            "  inflating: CASIA1/103/103_2_3.jpg  \n",
            "  inflating: CASIA1/103/103_2_4.jpg  \n",
            "   creating: CASIA1/104/\n",
            " extracting: CASIA1/104/104_1_1.jpg  \n",
            "  inflating: CASIA1/104/104_1_2.jpg  \n",
            "  inflating: CASIA1/104/104_1_3.jpg  \n",
            "  inflating: CASIA1/104/104_2_1.jpg  \n",
            "  inflating: CASIA1/104/104_2_2.jpg  \n",
            "  inflating: CASIA1/104/104_2_3.jpg  \n",
            "  inflating: CASIA1/104/104_2_4.jpg  \n",
            "   creating: CASIA1/105/\n",
            "  inflating: CASIA1/105/105_1_1.jpg  \n",
            "  inflating: CASIA1/105/105_1_2.jpg  \n",
            "  inflating: CASIA1/105/105_1_3.jpg  \n",
            "  inflating: CASIA1/105/105_2_1.jpg  \n",
            "  inflating: CASIA1/105/105_2_2.jpg  \n",
            "  inflating: CASIA1/105/105_2_3.jpg  \n",
            "  inflating: CASIA1/105/105_2_4.jpg  \n",
            "   creating: CASIA1/106/\n",
            "  inflating: CASIA1/106/106_1_1.jpg  \n",
            "  inflating: CASIA1/106/106_1_2.jpg  \n",
            "  inflating: CASIA1/106/106_1_3.jpg  \n",
            "  inflating: CASIA1/106/106_2_1.jpg  \n",
            "  inflating: CASIA1/106/106_2_2.jpg  \n",
            "  inflating: CASIA1/106/106_2_3.jpg  \n",
            "  inflating: CASIA1/106/106_2_4.jpg  \n",
            "   creating: CASIA1/107/\n",
            "  inflating: CASIA1/107/107_1_1.jpg  \n",
            "  inflating: CASIA1/107/107_1_2.jpg  \n",
            "  inflating: CASIA1/107/107_1_3.jpg  \n",
            "  inflating: CASIA1/107/107_2_1.jpg  \n",
            "  inflating: CASIA1/107/107_2_2.jpg  \n",
            "  inflating: CASIA1/107/107_2_3.jpg  \n",
            "  inflating: CASIA1/107/107_2_4.jpg  \n",
            "   creating: CASIA1/108/\n",
            "  inflating: CASIA1/108/108_1_1.jpg  \n",
            "  inflating: CASIA1/108/108_1_2.jpg  \n",
            "  inflating: CASIA1/108/108_1_3.jpg  \n",
            "  inflating: CASIA1/108/108_2_1.jpg  \n",
            "  inflating: CASIA1/108/108_2_2.jpg  \n",
            "  inflating: CASIA1/108/108_2_3.jpg  \n",
            "  inflating: CASIA1/108/108_2_4.jpg  \n",
            "   creating: CASIA1/11/\n",
            "  inflating: CASIA1/11/011_1_1.jpg   \n",
            "  inflating: CASIA1/11/011_1_2.jpg   \n",
            "  inflating: CASIA1/11/011_1_3.jpg   \n",
            "  inflating: CASIA1/11/011_2_1.jpg   \n",
            "  inflating: CASIA1/11/011_2_2.jpg   \n",
            "  inflating: CASIA1/11/011_2_3.jpg   \n",
            "  inflating: CASIA1/11/011_2_4.jpg   \n",
            "   creating: CASIA1/12/\n",
            "  inflating: CASIA1/12/012_1_1.jpg   \n",
            "  inflating: CASIA1/12/012_1_2.jpg   \n",
            "  inflating: CASIA1/12/012_1_3.jpg   \n",
            "  inflating: CASIA1/12/012_2_1.jpg   \n",
            "  inflating: CASIA1/12/012_2_2.jpg   \n",
            "  inflating: CASIA1/12/012_2_3.jpg   \n",
            "  inflating: CASIA1/12/012_2_4.jpg   \n",
            "   creating: CASIA1/13/\n",
            "  inflating: CASIA1/13/013_1_1.jpg   \n",
            "  inflating: CASIA1/13/013_1_2.jpg   \n",
            "  inflating: CASIA1/13/013_1_3.jpg   \n",
            "  inflating: CASIA1/13/013_2_1.jpg   \n",
            "  inflating: CASIA1/13/013_2_2.jpg   \n",
            "  inflating: CASIA1/13/013_2_3.jpg   \n",
            "  inflating: CASIA1/13/013_2_4.jpg   \n",
            "   creating: CASIA1/14/\n",
            "  inflating: CASIA1/14/014_1_1.jpg   \n",
            "  inflating: CASIA1/14/014_1_2.jpg   \n",
            " extracting: CASIA1/14/014_1_3.jpg   \n",
            " extracting: CASIA1/14/014_2_1.jpg   \n",
            " extracting: CASIA1/14/014_2_2.jpg   \n",
            "  inflating: CASIA1/14/014_2_3.jpg   \n",
            " extracting: CASIA1/14/014_2_4.jpg   \n",
            "   creating: CASIA1/15/\n",
            "  inflating: CASIA1/15/015_1_1.jpg   \n",
            "  inflating: CASIA1/15/015_1_2.jpg   \n",
            "  inflating: CASIA1/15/015_1_3.jpg   \n",
            "  inflating: CASIA1/15/015_2_1.jpg   \n",
            "  inflating: CASIA1/15/015_2_2.jpg   \n",
            "  inflating: CASIA1/15/015_2_3.jpg   \n",
            "  inflating: CASIA1/15/015_2_4.jpg   \n",
            "   creating: CASIA1/16/\n",
            "  inflating: CASIA1/16/016_1_1.jpg   \n",
            "  inflating: CASIA1/16/016_1_2.jpg   \n",
            " extracting: CASIA1/16/016_1_3.jpg   \n",
            " extracting: CASIA1/16/016_2_1.jpg   \n",
            "  inflating: CASIA1/16/016_2_2.jpg   \n",
            "  inflating: CASIA1/16/016_2_3.jpg   \n",
            "  inflating: CASIA1/16/016_2_4.jpg   \n",
            "   creating: CASIA1/17/\n",
            "  inflating: CASIA1/17/017_1_1.jpg   \n",
            "  inflating: CASIA1/17/017_1_2.jpg   \n",
            "  inflating: CASIA1/17/017_1_3.jpg   \n",
            " extracting: CASIA1/17/017_2_1.jpg   \n",
            "  inflating: CASIA1/17/017_2_2.jpg   \n",
            "  inflating: CASIA1/17/017_2_3.jpg   \n",
            "  inflating: CASIA1/17/017_2_4.jpg   \n",
            "   creating: CASIA1/18/\n",
            "  inflating: CASIA1/18/018_1_1.jpg   \n",
            "  inflating: CASIA1/18/018_1_2.jpg   \n",
            "  inflating: CASIA1/18/018_1_3.jpg   \n",
            "  inflating: CASIA1/18/018_2_1.jpg   \n",
            "  inflating: CASIA1/18/018_2_2.jpg   \n",
            "  inflating: CASIA1/18/018_2_3.jpg   \n",
            "  inflating: CASIA1/18/018_2_4.jpg   \n",
            "   creating: CASIA1/19/\n",
            "  inflating: CASIA1/19/019_1_1.jpg   \n",
            " extracting: CASIA1/19/019_1_2.jpg   \n",
            " extracting: CASIA1/19/019_1_3.jpg   \n",
            " extracting: CASIA1/19/019_2_1.jpg   \n",
            " extracting: CASIA1/19/019_2_2.jpg   \n",
            " extracting: CASIA1/19/019_2_3.jpg   \n",
            " extracting: CASIA1/19/019_2_4.jpg   \n",
            "   creating: CASIA1/2/\n",
            "  inflating: CASIA1/2/002_1_1.jpg    \n",
            "  inflating: CASIA1/2/002_1_2.jpg    \n",
            "  inflating: CASIA1/2/002_1_3.jpg    \n",
            "  inflating: CASIA1/2/002_2_1.jpg    \n",
            "  inflating: CASIA1/2/002_2_2.jpg    \n",
            "  inflating: CASIA1/2/002_2_3.jpg    \n",
            "  inflating: CASIA1/2/002_2_4.jpg    \n",
            "   creating: CASIA1/20/\n",
            "  inflating: CASIA1/20/020_1_1.jpg   \n",
            "  inflating: CASIA1/20/020_1_2.jpg   \n",
            "  inflating: CASIA1/20/020_1_3.jpg   \n",
            "  inflating: CASIA1/20/020_2_1.jpg   \n",
            "  inflating: CASIA1/20/020_2_2.jpg   \n",
            "  inflating: CASIA1/20/020_2_3.jpg   \n",
            "  inflating: CASIA1/20/020_2_4.jpg   \n",
            "   creating: CASIA1/21/\n",
            " extracting: CASIA1/21/021_1_1.jpg   \n",
            " extracting: CASIA1/21/021_1_2.jpg   \n",
            "  inflating: CASIA1/21/021_1_3.jpg   \n",
            " extracting: CASIA1/21/021_2_1.jpg   \n",
            " extracting: CASIA1/21/021_2_2.jpg   \n",
            " extracting: CASIA1/21/021_2_3.jpg   \n",
            " extracting: CASIA1/21/021_2_4.jpg   \n",
            "   creating: CASIA1/22/\n",
            "  inflating: CASIA1/22/022_1_1.jpg   \n",
            "  inflating: CASIA1/22/022_1_2.jpg   \n",
            "  inflating: CASIA1/22/022_1_3.jpg   \n",
            "  inflating: CASIA1/22/022_2_1.jpg   \n",
            "  inflating: CASIA1/22/022_2_2.jpg   \n",
            "  inflating: CASIA1/22/022_2_3.jpg   \n",
            "  inflating: CASIA1/22/022_2_4.jpg   \n",
            "   creating: CASIA1/23/\n",
            " extracting: CASIA1/23/023_1_1.jpg   \n",
            "  inflating: CASIA1/23/023_1_2.jpg   \n",
            "  inflating: CASIA1/23/023_1_3.jpg   \n",
            "  inflating: CASIA1/23/023_2_1.jpg   \n",
            " extracting: CASIA1/23/023_2_2.jpg   \n",
            "  inflating: CASIA1/23/023_2_3.jpg   \n",
            " extracting: CASIA1/23/023_2_4.jpg   \n",
            "   creating: CASIA1/24/\n",
            "  inflating: CASIA1/24/024_1_1.jpg   \n",
            "  inflating: CASIA1/24/024_1_2.jpg   \n",
            "  inflating: CASIA1/24/024_1_3.jpg   \n",
            " extracting: CASIA1/24/024_2_1.jpg   \n",
            " extracting: CASIA1/24/024_2_2.jpg   \n",
            " extracting: CASIA1/24/024_2_3.jpg   \n",
            "  inflating: CASIA1/24/024_2_4.jpg   \n",
            "   creating: CASIA1/25/\n",
            "  inflating: CASIA1/25/025_1_1.jpg   \n",
            "  inflating: CASIA1/25/025_1_2.jpg   \n",
            "  inflating: CASIA1/25/025_1_3.jpg   \n",
            "  inflating: CASIA1/25/025_2_1.jpg   \n",
            "  inflating: CASIA1/25/025_2_2.jpg   \n",
            "  inflating: CASIA1/25/025_2_3.jpg   \n",
            "  inflating: CASIA1/25/025_2_4.jpg   \n",
            "   creating: CASIA1/26/\n",
            "  inflating: CASIA1/26/026_1_1.jpg   \n",
            "  inflating: CASIA1/26/026_1_2.jpg   \n",
            "  inflating: CASIA1/26/026_1_3.jpg   \n",
            "  inflating: CASIA1/26/026_2_1.jpg   \n",
            "  inflating: CASIA1/26/026_2_2.jpg   \n",
            "  inflating: CASIA1/26/026_2_3.jpg   \n",
            "  inflating: CASIA1/26/026_2_4.jpg   \n",
            "   creating: CASIA1/27/\n",
            " extracting: CASIA1/27/027_1_1.jpg   \n",
            "  inflating: CASIA1/27/027_1_2.jpg   \n",
            " extracting: CASIA1/27/027_1_3.jpg   \n",
            " extracting: CASIA1/27/027_2_1.jpg   \n",
            " extracting: CASIA1/27/027_2_2.jpg   \n",
            "  inflating: CASIA1/27/027_2_3.jpg   \n",
            "  inflating: CASIA1/27/027_2_4.jpg   \n",
            "   creating: CASIA1/28/\n",
            " extracting: CASIA1/28/028_1_1.jpg   \n",
            "  inflating: CASIA1/28/028_1_2.jpg   \n",
            " extracting: CASIA1/28/028_1_3.jpg   \n",
            "  inflating: CASIA1/28/028_2_1.jpg   \n",
            " extracting: CASIA1/28/028_2_2.jpg   \n",
            "  inflating: CASIA1/28/028_2_3.jpg   \n",
            " extracting: CASIA1/28/028_2_4.jpg   \n",
            "   creating: CASIA1/29/\n",
            "  inflating: CASIA1/29/029_1_1.jpg   \n",
            "  inflating: CASIA1/29/029_1_2.jpg   \n",
            "  inflating: CASIA1/29/029_1_3.jpg   \n",
            " extracting: CASIA1/29/029_2_1.jpg   \n",
            "  inflating: CASIA1/29/029_2_2.jpg   \n",
            "  inflating: CASIA1/29/029_2_3.jpg   \n",
            "  inflating: CASIA1/29/029_2_4.jpg   \n",
            "   creating: CASIA1/3/\n",
            " extracting: CASIA1/3/003_1_1.jpg    \n",
            " extracting: CASIA1/3/003_1_2.jpg    \n",
            " extracting: CASIA1/3/003_1_3.jpg    \n",
            "  inflating: CASIA1/3/003_2_1.jpg    \n",
            " extracting: CASIA1/3/003_2_2.jpg    \n",
            " extracting: CASIA1/3/003_2_3.jpg    \n",
            " extracting: CASIA1/3/003_2_4.jpg    \n",
            "   creating: CASIA1/30/\n",
            "  inflating: CASIA1/30/030_1_1.jpg   \n",
            "  inflating: CASIA1/30/030_1_2.jpg   \n",
            "  inflating: CASIA1/30/030_1_3.jpg   \n",
            " extracting: CASIA1/30/030_2_1.jpg   \n",
            "  inflating: CASIA1/30/030_2_2.jpg   \n",
            "  inflating: CASIA1/30/030_2_3.jpg   \n",
            "  inflating: CASIA1/30/030_2_4.jpg   \n",
            "   creating: CASIA1/31/\n",
            "  inflating: CASIA1/31/031_1_1.jpg   \n",
            "  inflating: CASIA1/31/031_1_2.jpg   \n",
            "  inflating: CASIA1/31/031_1_3.jpg   \n",
            "  inflating: CASIA1/31/031_2_1.jpg   \n",
            "  inflating: CASIA1/31/031_2_2.jpg   \n",
            "  inflating: CASIA1/31/031_2_3.jpg   \n",
            " extracting: CASIA1/31/031_2_4.jpg   \n",
            "   creating: CASIA1/32/\n",
            "  inflating: CASIA1/32/032_1_1.jpg   \n",
            "  inflating: CASIA1/32/032_1_2.jpg   \n",
            " extracting: CASIA1/32/032_1_3.jpg   \n",
            "  inflating: CASIA1/32/032_2_1.jpg   \n",
            " extracting: CASIA1/32/032_2_2.jpg   \n",
            " extracting: CASIA1/32/032_2_3.jpg   \n",
            " extracting: CASIA1/32/032_2_4.jpg   \n",
            "   creating: CASIA1/33/\n",
            "  inflating: CASIA1/33/033_1_1.jpg   \n",
            "  inflating: CASIA1/33/033_1_2.jpg   \n",
            "  inflating: CASIA1/33/033_1_3.jpg   \n",
            "  inflating: CASIA1/33/033_2_1.jpg   \n",
            "  inflating: CASIA1/33/033_2_2.jpg   \n",
            "  inflating: CASIA1/33/033_2_3.jpg   \n",
            "  inflating: CASIA1/33/033_2_4.jpg   \n",
            "   creating: CASIA1/34/\n",
            "  inflating: CASIA1/34/034_1_1.jpg   \n",
            "  inflating: CASIA1/34/034_1_2.jpg   \n",
            "  inflating: CASIA1/34/034_1_3.jpg   \n",
            "  inflating: CASIA1/34/034_2_1.jpg   \n",
            "  inflating: CASIA1/34/034_2_2.jpg   \n",
            "  inflating: CASIA1/34/034_2_3.jpg   \n",
            "  inflating: CASIA1/34/034_2_4.jpg   \n",
            "   creating: CASIA1/35/\n",
            "  inflating: CASIA1/35/035_1_1.jpg   \n",
            "  inflating: CASIA1/35/035_1_2.jpg   \n",
            "  inflating: CASIA1/35/035_1_3.jpg   \n",
            " extracting: CASIA1/35/035_2_1.jpg   \n",
            "  inflating: CASIA1/35/035_2_2.jpg   \n",
            " extracting: CASIA1/35/035_2_3.jpg   \n",
            " extracting: CASIA1/35/035_2_4.jpg   \n",
            "   creating: CASIA1/36/\n",
            "  inflating: CASIA1/36/036_1_1.jpg   \n",
            "  inflating: CASIA1/36/036_1_2.jpg   \n",
            "  inflating: CASIA1/36/036_1_3.jpg   \n",
            "  inflating: CASIA1/36/036_2_1.jpg   \n",
            "  inflating: CASIA1/36/036_2_2.jpg   \n",
            "  inflating: CASIA1/36/036_2_3.jpg   \n",
            "  inflating: CASIA1/36/036_2_4.jpg   \n",
            "   creating: CASIA1/37/\n",
            "  inflating: CASIA1/37/037_1_1.jpg   \n",
            "  inflating: CASIA1/37/037_1_2.jpg   \n",
            "  inflating: CASIA1/37/037_1_3.jpg   \n",
            "  inflating: CASIA1/37/037_2_1.jpg   \n",
            "  inflating: CASIA1/37/037_2_2.jpg   \n",
            "  inflating: CASIA1/37/037_2_3.jpg   \n",
            "  inflating: CASIA1/37/037_2_4.jpg   \n",
            "   creating: CASIA1/38/\n",
            "  inflating: CASIA1/38/038_1_1.jpg   \n",
            "  inflating: CASIA1/38/038_1_2.jpg   \n",
            "  inflating: CASIA1/38/038_1_3.jpg   \n",
            "  inflating: CASIA1/38/038_2_1.jpg   \n",
            "  inflating: CASIA1/38/038_2_2.jpg   \n",
            "  inflating: CASIA1/38/038_2_3.jpg   \n",
            "  inflating: CASIA1/38/038_2_4.jpg   \n",
            "   creating: CASIA1/39/\n",
            "  inflating: CASIA1/39/039_1_1.jpg   \n",
            "  inflating: CASIA1/39/039_1_2.jpg   \n",
            "  inflating: CASIA1/39/039_1_3.jpg   \n",
            "  inflating: CASIA1/39/039_2_1.jpg   \n",
            "  inflating: CASIA1/39/039_2_2.jpg   \n",
            "  inflating: CASIA1/39/039_2_3.jpg   \n",
            "  inflating: CASIA1/39/039_2_4.jpg   \n",
            "   creating: CASIA1/4/\n",
            "  inflating: CASIA1/4/004_1_1.jpg    \n",
            "  inflating: CASIA1/4/004_1_2.jpg    \n",
            "  inflating: CASIA1/4/004_1_3.jpg    \n",
            "  inflating: CASIA1/4/004_2_1.jpg    \n",
            "  inflating: CASIA1/4/004_2_2.jpg    \n",
            "  inflating: CASIA1/4/004_2_3.jpg    \n",
            "  inflating: CASIA1/4/004_2_4.jpg    \n",
            "   creating: CASIA1/40/\n",
            " extracting: CASIA1/40/040_1_1.jpg   \n",
            "  inflating: CASIA1/40/040_1_2.jpg   \n",
            "  inflating: CASIA1/40/040_1_3.jpg   \n",
            " extracting: CASIA1/40/040_2_1.jpg   \n",
            " extracting: CASIA1/40/040_2_2.jpg   \n",
            " extracting: CASIA1/40/040_2_3.jpg   \n",
            " extracting: CASIA1/40/040_2_4.jpg   \n",
            "   creating: CASIA1/41/\n",
            "  inflating: CASIA1/41/041_1_1.jpg   \n",
            "  inflating: CASIA1/41/041_1_2.jpg   \n",
            "  inflating: CASIA1/41/041_1_3.jpg   \n",
            "  inflating: CASIA1/41/041_2_1.jpg   \n",
            "  inflating: CASIA1/41/041_2_2.jpg   \n",
            "  inflating: CASIA1/41/041_2_3.jpg   \n",
            "  inflating: CASIA1/41/041_2_4.jpg   \n",
            "   creating: CASIA1/42/\n",
            "  inflating: CASIA1/42/042_1_1.jpg   \n",
            " extracting: CASIA1/42/042_1_2.jpg   \n",
            "  inflating: CASIA1/42/042_1_3.jpg   \n",
            " extracting: CASIA1/42/042_2_1.jpg   \n",
            " extracting: CASIA1/42/042_2_2.jpg   \n",
            " extracting: CASIA1/42/042_2_3.jpg   \n",
            " extracting: CASIA1/42/042_2_4.jpg   \n",
            "   creating: CASIA1/43/\n",
            "  inflating: CASIA1/43/043_1_1.jpg   \n",
            "  inflating: CASIA1/43/043_1_2.jpg   \n",
            "  inflating: CASIA1/43/043_1_3.jpg   \n",
            "  inflating: CASIA1/43/043_2_1.jpg   \n",
            "  inflating: CASIA1/43/043_2_2.jpg   \n",
            "  inflating: CASIA1/43/043_2_3.jpg   \n",
            "  inflating: CASIA1/43/043_2_4.jpg   \n",
            "   creating: CASIA1/44/\n",
            "  inflating: CASIA1/44/044_1_1.jpg   \n",
            "  inflating: CASIA1/44/044_1_2.jpg   \n",
            "  inflating: CASIA1/44/044_1_3.jpg   \n",
            "  inflating: CASIA1/44/044_2_1.jpg   \n",
            "  inflating: CASIA1/44/044_2_2.jpg   \n",
            "  inflating: CASIA1/44/044_2_3.jpg   \n",
            "  inflating: CASIA1/44/044_2_4.jpg   \n",
            "   creating: CASIA1/45/\n",
            "  inflating: CASIA1/45/045_1_1.jpg   \n",
            " extracting: CASIA1/45/045_1_2.jpg   \n",
            "  inflating: CASIA1/45/045_1_3.jpg   \n",
            "  inflating: CASIA1/45/045_2_1.jpg   \n",
            " extracting: CASIA1/45/045_2_2.jpg   \n",
            "  inflating: CASIA1/45/045_2_3.jpg   \n",
            "  inflating: CASIA1/45/045_2_4.jpg   \n",
            "   creating: CASIA1/46/\n",
            "  inflating: CASIA1/46/046_1_1.jpg   \n",
            "  inflating: CASIA1/46/046_1_2.jpg   \n",
            "  inflating: CASIA1/46/046_1_3.jpg   \n",
            "  inflating: CASIA1/46/046_2_1.jpg   \n",
            "  inflating: CASIA1/46/046_2_2.jpg   \n",
            "  inflating: CASIA1/46/046_2_3.jpg   \n",
            "  inflating: CASIA1/46/046_2_4.jpg   \n",
            "   creating: CASIA1/47/\n",
            "  inflating: CASIA1/47/047_1_1.jpg   \n",
            "  inflating: CASIA1/47/047_1_2.jpg   \n",
            "  inflating: CASIA1/47/047_1_3.jpg   \n",
            "  inflating: CASIA1/47/047_2_1.jpg   \n",
            "  inflating: CASIA1/47/047_2_2.jpg   \n",
            "  inflating: CASIA1/47/047_2_3.jpg   \n",
            "  inflating: CASIA1/47/047_2_4.jpg   \n",
            "   creating: CASIA1/48/\n",
            "  inflating: CASIA1/48/048_1_1.jpg   \n",
            "  inflating: CASIA1/48/048_1_2.jpg   \n",
            "  inflating: CASIA1/48/048_1_3.jpg   \n",
            " extracting: CASIA1/48/048_2_1.jpg   \n",
            " extracting: CASIA1/48/048_2_2.jpg   \n",
            "  inflating: CASIA1/48/048_2_3.jpg   \n",
            "  inflating: CASIA1/48/048_2_4.jpg   \n",
            "   creating: CASIA1/49/\n",
            "  inflating: CASIA1/49/049_1_1.jpg   \n",
            "  inflating: CASIA1/49/049_1_2.jpg   \n",
            "  inflating: CASIA1/49/049_1_3.jpg   \n",
            "  inflating: CASIA1/49/049_2_1.jpg   \n",
            "  inflating: CASIA1/49/049_2_2.jpg   \n",
            "  inflating: CASIA1/49/049_2_3.jpg   \n",
            "  inflating: CASIA1/49/049_2_4.jpg   \n",
            "   creating: CASIA1/5/\n",
            "  inflating: CASIA1/5/005_1_1.jpg    \n",
            "  inflating: CASIA1/5/005_1_2.jpg    \n",
            "  inflating: CASIA1/5/005_1_3.jpg    \n",
            "  inflating: CASIA1/5/005_2_1.jpg    \n",
            "  inflating: CASIA1/5/005_2_2.jpg    \n",
            " extracting: CASIA1/5/005_2_3.jpg    \n",
            "  inflating: CASIA1/5/005_2_4.jpg    \n",
            "   creating: CASIA1/50/\n",
            "  inflating: CASIA1/50/050_1_1.jpg   \n",
            "  inflating: CASIA1/50/050_1_2.jpg   \n",
            "  inflating: CASIA1/50/050_1_3.jpg   \n",
            "  inflating: CASIA1/50/050_2_1.jpg   \n",
            "  inflating: CASIA1/50/050_2_2.jpg   \n",
            "  inflating: CASIA1/50/050_2_3.jpg   \n",
            "  inflating: CASIA1/50/050_2_4.jpg   \n",
            "   creating: CASIA1/51/\n",
            "  inflating: CASIA1/51/051_1_1.jpg   \n",
            "  inflating: CASIA1/51/051_1_2.jpg   \n",
            "  inflating: CASIA1/51/051_1_3.jpg   \n",
            "  inflating: CASIA1/51/051_2_1.jpg   \n",
            "  inflating: CASIA1/51/051_2_2.jpg   \n",
            "  inflating: CASIA1/51/051_2_3.jpg   \n",
            "  inflating: CASIA1/51/051_2_4.jpg   \n",
            "   creating: CASIA1/52/\n",
            "  inflating: CASIA1/52/052_1_1.jpg   \n",
            "  inflating: CASIA1/52/052_1_2.jpg   \n",
            "  inflating: CASIA1/52/052_1_3.jpg   \n",
            "  inflating: CASIA1/52/052_2_1.jpg   \n",
            "  inflating: CASIA1/52/052_2_2.jpg   \n",
            "  inflating: CASIA1/52/052_2_3.jpg   \n",
            "  inflating: CASIA1/52/052_2_4.jpg   \n",
            "   creating: CASIA1/53/\n",
            "  inflating: CASIA1/53/053_1_1.jpg   \n",
            "  inflating: CASIA1/53/053_1_2.jpg   \n",
            "  inflating: CASIA1/53/053_1_3.jpg   \n",
            "  inflating: CASIA1/53/053_2_1.jpg   \n",
            "  inflating: CASIA1/53/053_2_2.jpg   \n",
            "  inflating: CASIA1/53/053_2_3.jpg   \n",
            "  inflating: CASIA1/53/053_2_4.jpg   \n",
            "   creating: CASIA1/54/\n",
            "  inflating: CASIA1/54/054_1_1.jpg   \n",
            "  inflating: CASIA1/54/054_1_2.jpg   \n",
            "  inflating: CASIA1/54/054_1_3.jpg   \n",
            "  inflating: CASIA1/54/054_2_1.jpg   \n",
            "  inflating: CASIA1/54/054_2_2.jpg   \n",
            "  inflating: CASIA1/54/054_2_3.jpg   \n",
            "  inflating: CASIA1/54/054_2_4.jpg   \n",
            "   creating: CASIA1/55/\n",
            " extracting: CASIA1/55/055_1_1.jpg   \n",
            " extracting: CASIA1/55/055_1_2.jpg   \n",
            "  inflating: CASIA1/55/055_1_3.jpg   \n",
            " extracting: CASIA1/55/055_2_1.jpg   \n",
            " extracting: CASIA1/55/055_2_2.jpg   \n",
            " extracting: CASIA1/55/055_2_3.jpg   \n",
            " extracting: CASIA1/55/055_2_4.jpg   \n",
            "   creating: CASIA1/56/\n",
            "  inflating: CASIA1/56/056_1_1.jpg   \n",
            "  inflating: CASIA1/56/056_1_2.jpg   \n",
            "  inflating: CASIA1/56/056_1_3.jpg   \n",
            "  inflating: CASIA1/56/056_2_1.jpg   \n",
            "  inflating: CASIA1/56/056_2_2.jpg   \n",
            "  inflating: CASIA1/56/056_2_3.jpg   \n",
            "  inflating: CASIA1/56/056_2_4.jpg   \n",
            "   creating: CASIA1/57/\n",
            "  inflating: CASIA1/57/057_1_1.jpg   \n",
            "  inflating: CASIA1/57/057_1_2.jpg   \n",
            "  inflating: CASIA1/57/057_1_3.jpg   \n",
            " extracting: CASIA1/57/057_2_1.jpg   \n",
            " extracting: CASIA1/57/057_2_2.jpg   \n",
            "  inflating: CASIA1/57/057_2_3.jpg   \n",
            "  inflating: CASIA1/57/057_2_4.jpg   \n",
            "   creating: CASIA1/58/\n",
            "  inflating: CASIA1/58/058_1_1.jpg   \n",
            "  inflating: CASIA1/58/058_1_2.jpg   \n",
            "  inflating: CASIA1/58/058_1_3.jpg   \n",
            "  inflating: CASIA1/58/058_2_1.jpg   \n",
            "  inflating: CASIA1/58/058_2_2.jpg   \n",
            "  inflating: CASIA1/58/058_2_3.jpg   \n",
            "  inflating: CASIA1/58/058_2_4.jpg   \n",
            "   creating: CASIA1/59/\n",
            "  inflating: CASIA1/59/059_1_1.jpg   \n",
            "  inflating: CASIA1/59/059_1_2.jpg   \n",
            "  inflating: CASIA1/59/059_1_3.jpg   \n",
            "  inflating: CASIA1/59/059_2_1.jpg   \n",
            " extracting: CASIA1/59/059_2_2.jpg   \n",
            "  inflating: CASIA1/59/059_2_3.jpg   \n",
            "  inflating: CASIA1/59/059_2_4.jpg   \n",
            "   creating: CASIA1/6/\n",
            "  inflating: CASIA1/6/006_1_1.jpg    \n",
            "  inflating: CASIA1/6/006_1_2.jpg    \n",
            "  inflating: CASIA1/6/006_1_3.jpg    \n",
            "  inflating: CASIA1/6/006_2_1.jpg    \n",
            "  inflating: CASIA1/6/006_2_2.jpg    \n",
            "  inflating: CASIA1/6/006_2_3.jpg    \n",
            " extracting: CASIA1/6/006_2_4.jpg    \n",
            "   creating: CASIA1/60/\n",
            " extracting: CASIA1/60/060_1_1.jpg   \n",
            "  inflating: CASIA1/60/060_1_2.jpg   \n",
            " extracting: CASIA1/60/060_1_3.jpg   \n",
            " extracting: CASIA1/60/060_2_1.jpg   \n",
            " extracting: CASIA1/60/060_2_2.jpg   \n",
            "  inflating: CASIA1/60/060_2_3.jpg   \n",
            "  inflating: CASIA1/60/060_2_4.jpg   \n",
            "   creating: CASIA1/61/\n",
            "  inflating: CASIA1/61/061_1_1.jpg   \n",
            "  inflating: CASIA1/61/061_1_2.jpg   \n",
            "  inflating: CASIA1/61/061_1_3.jpg   \n",
            "  inflating: CASIA1/61/061_2_1.jpg   \n",
            "  inflating: CASIA1/61/061_2_2.jpg   \n",
            " extracting: CASIA1/61/061_2_3.jpg   \n",
            " extracting: CASIA1/61/061_2_4.jpg   \n",
            "   creating: CASIA1/62/\n",
            "  inflating: CASIA1/62/062_1_1.jpg   \n",
            "  inflating: CASIA1/62/062_1_2.jpg   \n",
            "  inflating: CASIA1/62/062_1_3.jpg   \n",
            "  inflating: CASIA1/62/062_2_1.jpg   \n",
            "  inflating: CASIA1/62/062_2_2.jpg   \n",
            "  inflating: CASIA1/62/062_2_3.jpg   \n",
            "  inflating: CASIA1/62/062_2_4.jpg   \n",
            "   creating: CASIA1/63/\n",
            "  inflating: CASIA1/63/063_1_1.jpg   \n",
            "  inflating: CASIA1/63/063_1_2.jpg   \n",
            "  inflating: CASIA1/63/063_1_3.jpg   \n",
            "  inflating: CASIA1/63/063_2_1.jpg   \n",
            "  inflating: CASIA1/63/063_2_2.jpg   \n",
            "  inflating: CASIA1/63/063_2_3.jpg   \n",
            "  inflating: CASIA1/63/063_2_4.jpg   \n",
            "   creating: CASIA1/64/\n",
            "  inflating: CASIA1/64/064_1_1.jpg   \n",
            "  inflating: CASIA1/64/064_1_2.jpg   \n",
            " extracting: CASIA1/64/064_1_3.jpg   \n",
            " extracting: CASIA1/64/064_2_1.jpg   \n",
            " extracting: CASIA1/64/064_2_2.jpg   \n",
            " extracting: CASIA1/64/064_2_3.jpg   \n",
            "  inflating: CASIA1/64/064_2_4.jpg   \n",
            "   creating: CASIA1/65/\n",
            "  inflating: CASIA1/65/065_1_1.jpg   \n",
            "  inflating: CASIA1/65/065_1_2.jpg   \n",
            "  inflating: CASIA1/65/065_1_3.jpg   \n",
            "  inflating: CASIA1/65/065_2_1.jpg   \n",
            " extracting: CASIA1/65/065_2_2.jpg   \n",
            "  inflating: CASIA1/65/065_2_3.jpg   \n",
            "  inflating: CASIA1/65/065_2_4.jpg   \n",
            "   creating: CASIA1/66/\n",
            "  inflating: CASIA1/66/066_1_1.jpg   \n",
            "  inflating: CASIA1/66/066_1_2.jpg   \n",
            "  inflating: CASIA1/66/066_1_3.jpg   \n",
            "  inflating: CASIA1/66/066_2_1.jpg   \n",
            "  inflating: CASIA1/66/066_2_2.jpg   \n",
            " extracting: CASIA1/66/066_2_3.jpg   \n",
            "  inflating: CASIA1/66/066_2_4.jpg   \n",
            "   creating: CASIA1/67/\n",
            "  inflating: CASIA1/67/067_1_1.jpg   \n",
            "  inflating: CASIA1/67/067_1_2.jpg   \n",
            "  inflating: CASIA1/67/067_1_3.jpg   \n",
            "  inflating: CASIA1/67/067_2_1.jpg   \n",
            "  inflating: CASIA1/67/067_2_2.jpg   \n",
            "  inflating: CASIA1/67/067_2_3.jpg   \n",
            "  inflating: CASIA1/67/067_2_4.jpg   \n",
            "   creating: CASIA1/68/\n",
            "  inflating: CASIA1/68/068_1_1.jpg   \n",
            "  inflating: CASIA1/68/068_1_2.jpg   \n",
            "  inflating: CASIA1/68/068_1_3.jpg   \n",
            "  inflating: CASIA1/68/068_2_1.jpg   \n",
            " extracting: CASIA1/68/068_2_2.jpg   \n",
            "  inflating: CASIA1/68/068_2_3.jpg   \n",
            "  inflating: CASIA1/68/068_2_4.jpg   \n",
            "   creating: CASIA1/69/\n",
            "  inflating: CASIA1/69/069_1_1.jpg   \n",
            "  inflating: CASIA1/69/069_1_2.jpg   \n",
            "  inflating: CASIA1/69/069_1_3.jpg   \n",
            "  inflating: CASIA1/69/069_2_1.jpg   \n",
            "  inflating: CASIA1/69/069_2_2.jpg   \n",
            "  inflating: CASIA1/69/069_2_3.jpg   \n",
            "  inflating: CASIA1/69/069_2_4.jpg   \n",
            "   creating: CASIA1/7/\n",
            "  inflating: CASIA1/7/007_1_1.jpg    \n",
            " extracting: CASIA1/7/007_1_2.jpg    \n",
            "  inflating: CASIA1/7/007_1_3.jpg    \n",
            "  inflating: CASIA1/7/007_2_1.jpg    \n",
            "  inflating: CASIA1/7/007_2_2.jpg    \n",
            "  inflating: CASIA1/7/007_2_3.jpg    \n",
            "  inflating: CASIA1/7/007_2_4.jpg    \n",
            "   creating: CASIA1/70/\n",
            "  inflating: CASIA1/70/070_1_1.jpg   \n",
            "  inflating: CASIA1/70/070_1_2.jpg   \n",
            "  inflating: CASIA1/70/070_1_3.jpg   \n",
            "  inflating: CASIA1/70/070_2_1.jpg   \n",
            "  inflating: CASIA1/70/070_2_2.jpg   \n",
            "  inflating: CASIA1/70/070_2_3.jpg   \n",
            "  inflating: CASIA1/70/070_2_4.jpg   \n",
            "   creating: CASIA1/71/\n",
            "  inflating: CASIA1/71/071_1_1.jpg   \n",
            "  inflating: CASIA1/71/071_1_2.jpg   \n",
            "  inflating: CASIA1/71/071_1_3.jpg   \n",
            "  inflating: CASIA1/71/071_2_1.jpg   \n",
            "  inflating: CASIA1/71/071_2_2.jpg   \n",
            "  inflating: CASIA1/71/071_2_3.jpg   \n",
            "  inflating: CASIA1/71/071_2_4.jpg   \n",
            "   creating: CASIA1/72/\n",
            "  inflating: CASIA1/72/072_1_1.jpg   \n",
            "  inflating: CASIA1/72/072_1_2.jpg   \n",
            "  inflating: CASIA1/72/072_1_3.jpg   \n",
            "  inflating: CASIA1/72/072_2_1.jpg   \n",
            "  inflating: CASIA1/72/072_2_2.jpg   \n",
            "  inflating: CASIA1/72/072_2_3.jpg   \n",
            " extracting: CASIA1/72/072_2_4.jpg   \n",
            "   creating: CASIA1/73/\n",
            "  inflating: CASIA1/73/073_1_1.jpg   \n",
            "  inflating: CASIA1/73/073_1_2.jpg   \n",
            "  inflating: CASIA1/73/073_1_3.jpg   \n",
            "  inflating: CASIA1/73/073_2_1.jpg   \n",
            "  inflating: CASIA1/73/073_2_2.jpg   \n",
            "  inflating: CASIA1/73/073_2_3.jpg   \n",
            "  inflating: CASIA1/73/073_2_4.jpg   \n",
            "   creating: CASIA1/74/\n",
            "  inflating: CASIA1/74/074_1_1.jpg   \n",
            " extracting: CASIA1/74/074_1_2.jpg   \n",
            "  inflating: CASIA1/74/074_1_3.jpg   \n",
            "  inflating: CASIA1/74/074_2_1.jpg   \n",
            "  inflating: CASIA1/74/074_2_2.jpg   \n",
            "  inflating: CASIA1/74/074_2_3.jpg   \n",
            "  inflating: CASIA1/74/074_2_4.jpg   \n",
            "   creating: CASIA1/75/\n",
            "  inflating: CASIA1/75/075_1_1.jpg   \n",
            "  inflating: CASIA1/75/075_1_2.jpg   \n",
            "  inflating: CASIA1/75/075_1_3.jpg   \n",
            "  inflating: CASIA1/75/075_2_1.jpg   \n",
            " extracting: CASIA1/75/075_2_2.jpg   \n",
            "  inflating: CASIA1/75/075_2_3.jpg   \n",
            "  inflating: CASIA1/75/075_2_4.jpg   \n",
            "   creating: CASIA1/76/\n",
            "  inflating: CASIA1/76/076_1_1.jpg   \n",
            " extracting: CASIA1/76/076_1_2.jpg   \n",
            " extracting: CASIA1/76/076_1_3.jpg   \n",
            " extracting: CASIA1/76/076_2_1.jpg   \n",
            "  inflating: CASIA1/76/076_2_2.jpg   \n",
            " extracting: CASIA1/76/076_2_3.jpg   \n",
            " extracting: CASIA1/76/076_2_4.jpg   \n",
            "   creating: CASIA1/77/\n",
            "  inflating: CASIA1/77/077_1_1.jpg   \n",
            "  inflating: CASIA1/77/077_1_2.jpg   \n",
            "  inflating: CASIA1/77/077_1_3.jpg   \n",
            "  inflating: CASIA1/77/077_2_1.jpg   \n",
            "  inflating: CASIA1/77/077_2_2.jpg   \n",
            "  inflating: CASIA1/77/077_2_3.jpg   \n",
            "  inflating: CASIA1/77/077_2_4.jpg   \n",
            "   creating: CASIA1/78/\n",
            " extracting: CASIA1/78/078_1_1.jpg   \n",
            " extracting: CASIA1/78/078_1_2.jpg   \n",
            "  inflating: CASIA1/78/078_1_3.jpg   \n",
            "  inflating: CASIA1/78/078_2_1.jpg   \n",
            "  inflating: CASIA1/78/078_2_2.jpg   \n",
            "  inflating: CASIA1/78/078_2_3.jpg   \n",
            "  inflating: CASIA1/78/078_2_4.jpg   \n",
            "   creating: CASIA1/79/\n",
            "  inflating: CASIA1/79/079_1_1.jpg   \n",
            "  inflating: CASIA1/79/079_1_2.jpg   \n",
            "  inflating: CASIA1/79/079_1_3.jpg   \n",
            "  inflating: CASIA1/79/079_2_1.jpg   \n",
            "  inflating: CASIA1/79/079_2_2.jpg   \n",
            "  inflating: CASIA1/79/079_2_3.jpg   \n",
            "  inflating: CASIA1/79/079_2_4.jpg   \n",
            "   creating: CASIA1/8/\n",
            "  inflating: CASIA1/8/008_1_1.jpg    \n",
            "  inflating: CASIA1/8/008_1_2.jpg    \n",
            "  inflating: CASIA1/8/008_1_3.jpg    \n",
            " extracting: CASIA1/8/008_2_1.jpg    \n",
            "  inflating: CASIA1/8/008_2_2.jpg    \n",
            "  inflating: CASIA1/8/008_2_3.jpg    \n",
            "  inflating: CASIA1/8/008_2_4.jpg    \n",
            "   creating: CASIA1/80/\n",
            "  inflating: CASIA1/80/080_1_1.jpg   \n",
            " extracting: CASIA1/80/080_1_2.jpg   \n",
            "  inflating: CASIA1/80/080_1_3.jpg   \n",
            "  inflating: CASIA1/80/080_2_1.jpg   \n",
            "  inflating: CASIA1/80/080_2_2.jpg   \n",
            "  inflating: CASIA1/80/080_2_3.jpg   \n",
            "  inflating: CASIA1/80/080_2_4.jpg   \n",
            "   creating: CASIA1/81/\n",
            "  inflating: CASIA1/81/081_1_1.jpg   \n",
            "  inflating: CASIA1/81/081_1_2.jpg   \n",
            "  inflating: CASIA1/81/081_1_3.jpg   \n",
            "  inflating: CASIA1/81/081_2_1.jpg   \n",
            "  inflating: CASIA1/81/081_2_2.jpg   \n",
            "  inflating: CASIA1/81/081_2_3.jpg   \n",
            "  inflating: CASIA1/81/081_2_4.jpg   \n",
            "   creating: CASIA1/82/\n",
            "  inflating: CASIA1/82/082_1_1.jpg   \n",
            " extracting: CASIA1/82/082_1_2.jpg   \n",
            " extracting: CASIA1/82/082_1_3.jpg   \n",
            " extracting: CASIA1/82/082_2_1.jpg   \n",
            " extracting: CASIA1/82/082_2_2.jpg   \n",
            " extracting: CASIA1/82/082_2_3.jpg   \n",
            " extracting: CASIA1/82/082_2_4.jpg   \n",
            "   creating: CASIA1/83/\n",
            "  inflating: CASIA1/83/083_1_1.jpg   \n",
            "  inflating: CASIA1/83/083_1_2.jpg   \n",
            "  inflating: CASIA1/83/083_1_3.jpg   \n",
            "  inflating: CASIA1/83/083_2_1.jpg   \n",
            "  inflating: CASIA1/83/083_2_2.jpg   \n",
            "  inflating: CASIA1/83/083_2_3.jpg   \n",
            "  inflating: CASIA1/83/083_2_4.jpg   \n",
            "   creating: CASIA1/84/\n",
            "  inflating: CASIA1/84/084_1_1.jpg   \n",
            "  inflating: CASIA1/84/084_1_2.jpg   \n",
            "  inflating: CASIA1/84/084_1_3.jpg   \n",
            " extracting: CASIA1/84/084_2_1.jpg   \n",
            "  inflating: CASIA1/84/084_2_2.jpg   \n",
            "  inflating: CASIA1/84/084_2_3.jpg   \n",
            "  inflating: CASIA1/84/084_2_4.jpg   \n",
            "   creating: CASIA1/85/\n",
            "  inflating: CASIA1/85/085_1_1.jpg   \n",
            "  inflating: CASIA1/85/085_1_2.jpg   \n",
            "  inflating: CASIA1/85/085_1_3.jpg   \n",
            "  inflating: CASIA1/85/085_2_1.jpg   \n",
            "  inflating: CASIA1/85/085_2_2.jpg   \n",
            "  inflating: CASIA1/85/085_2_3.jpg   \n",
            "  inflating: CASIA1/85/085_2_4.jpg   \n",
            "   creating: CASIA1/86/\n",
            "  inflating: CASIA1/86/086_1_1.jpg   \n",
            " extracting: CASIA1/86/086_1_2.jpg   \n",
            "  inflating: CASIA1/86/086_1_3.jpg   \n",
            "  inflating: CASIA1/86/086_2_1.jpg   \n",
            "  inflating: CASIA1/86/086_2_2.jpg   \n",
            "  inflating: CASIA1/86/086_2_3.jpg   \n",
            "  inflating: CASIA1/86/086_2_4.jpg   \n",
            "   creating: CASIA1/87/\n",
            "  inflating: CASIA1/87/087_1_1.jpg   \n",
            " extracting: CASIA1/87/087_1_2.jpg   \n",
            "  inflating: CASIA1/87/087_1_3.jpg   \n",
            " extracting: CASIA1/87/087_2_1.jpg   \n",
            "  inflating: CASIA1/87/087_2_2.jpg   \n",
            "  inflating: CASIA1/87/087_2_3.jpg   \n",
            "  inflating: CASIA1/87/087_2_4.jpg   \n",
            "   creating: CASIA1/88/\n",
            "  inflating: CASIA1/88/088_1_1.jpg   \n",
            "  inflating: CASIA1/88/088_1_2.jpg   \n",
            "  inflating: CASIA1/88/088_1_3.jpg   \n",
            "  inflating: CASIA1/88/088_2_1.jpg   \n",
            "  inflating: CASIA1/88/088_2_2.jpg   \n",
            "  inflating: CASIA1/88/088_2_3.jpg   \n",
            "  inflating: CASIA1/88/088_2_4.jpg   \n",
            "   creating: CASIA1/89/\n",
            "  inflating: CASIA1/89/089_1_1.jpg   \n",
            "  inflating: CASIA1/89/089_1_2.jpg   \n",
            "  inflating: CASIA1/89/089_1_3.jpg   \n",
            "  inflating: CASIA1/89/089_2_1.jpg   \n",
            "  inflating: CASIA1/89/089_2_2.jpg   \n",
            "  inflating: CASIA1/89/089_2_3.jpg   \n",
            "  inflating: CASIA1/89/089_2_4.jpg   \n",
            "   creating: CASIA1/9/\n",
            "  inflating: CASIA1/9/009_1_1.jpg    \n",
            "  inflating: CASIA1/9/009_1_2.jpg    \n",
            "  inflating: CASIA1/9/009_1_3.jpg    \n",
            "  inflating: CASIA1/9/009_2_1.jpg    \n",
            "  inflating: CASIA1/9/009_2_2.jpg    \n",
            "  inflating: CASIA1/9/009_2_3.jpg    \n",
            "  inflating: CASIA1/9/009_2_4.jpg    \n",
            "   creating: CASIA1/90/\n",
            "  inflating: CASIA1/90/090_1_1.jpg   \n",
            "  inflating: CASIA1/90/090_1_2.jpg   \n",
            "  inflating: CASIA1/90/090_1_3.jpg   \n",
            "  inflating: CASIA1/90/090_2_1.jpg   \n",
            "  inflating: CASIA1/90/090_2_2.jpg   \n",
            "  inflating: CASIA1/90/090_2_3.jpg   \n",
            "  inflating: CASIA1/90/090_2_4.jpg   \n",
            "   creating: CASIA1/91/\n",
            "  inflating: CASIA1/91/091_1_1.jpg   \n",
            "  inflating: CASIA1/91/091_1_2.jpg   \n",
            "  inflating: CASIA1/91/091_1_3.jpg   \n",
            "  inflating: CASIA1/91/091_2_1.jpg   \n",
            "  inflating: CASIA1/91/091_2_2.jpg   \n",
            "  inflating: CASIA1/91/091_2_3.jpg   \n",
            "  inflating: CASIA1/91/091_2_4.jpg   \n",
            "   creating: CASIA1/92/\n",
            "  inflating: CASIA1/92/092_1_1.jpg   \n",
            "  inflating: CASIA1/92/092_1_2.jpg   \n",
            "  inflating: CASIA1/92/092_1_3.jpg   \n",
            "  inflating: CASIA1/92/092_2_1.jpg   \n",
            "  inflating: CASIA1/92/092_2_2.jpg   \n",
            "  inflating: CASIA1/92/092_2_3.jpg   \n",
            "  inflating: CASIA1/92/092_2_4.jpg   \n",
            "   creating: CASIA1/93/\n",
            "  inflating: CASIA1/93/093_1_1.jpg   \n",
            "  inflating: CASIA1/93/093_1_2.jpg   \n",
            "  inflating: CASIA1/93/093_1_3.jpg   \n",
            "  inflating: CASIA1/93/093_2_1.jpg   \n",
            "  inflating: CASIA1/93/093_2_2.jpg   \n",
            "  inflating: CASIA1/93/093_2_3.jpg   \n",
            "  inflating: CASIA1/93/093_2_4.jpg   \n",
            "   creating: CASIA1/94/\n",
            "  inflating: CASIA1/94/094_1_1.jpg   \n",
            " extracting: CASIA1/94/094_1_2.jpg   \n",
            " extracting: CASIA1/94/094_1_3.jpg   \n",
            "  inflating: CASIA1/94/094_2_1.jpg   \n",
            "  inflating: CASIA1/94/094_2_2.jpg   \n",
            "  inflating: CASIA1/94/094_2_3.jpg   \n",
            "  inflating: CASIA1/94/094_2_4.jpg   \n",
            "   creating: CASIA1/95/\n",
            "  inflating: CASIA1/95/095_1_1.jpg   \n",
            " extracting: CASIA1/95/095_1_2.jpg   \n",
            "  inflating: CASIA1/95/095_1_3.jpg   \n",
            "  inflating: CASIA1/95/095_2_1.jpg   \n",
            " extracting: CASIA1/95/095_2_2.jpg   \n",
            "  inflating: CASIA1/95/095_2_3.jpg   \n",
            "  inflating: CASIA1/95/095_2_4.jpg   \n",
            "   creating: CASIA1/96/\n",
            "  inflating: CASIA1/96/096_1_1.jpg   \n",
            "  inflating: CASIA1/96/096_1_2.jpg   \n",
            "  inflating: CASIA1/96/096_1_3.jpg   \n",
            "  inflating: CASIA1/96/096_2_1.jpg   \n",
            "  inflating: CASIA1/96/096_2_2.jpg   \n",
            "  inflating: CASIA1/96/096_2_3.jpg   \n",
            "  inflating: CASIA1/96/096_2_4.jpg   \n",
            "   creating: CASIA1/97/\n",
            "  inflating: CASIA1/97/097_1_1.jpg   \n",
            "  inflating: CASIA1/97/097_1_2.jpg   \n",
            "  inflating: CASIA1/97/097_1_3.jpg   \n",
            "  inflating: CASIA1/97/097_2_1.jpg   \n",
            "  inflating: CASIA1/97/097_2_2.jpg   \n",
            "  inflating: CASIA1/97/097_2_3.jpg   \n",
            "  inflating: CASIA1/97/097_2_4.jpg   \n",
            "   creating: CASIA1/98/\n",
            "  inflating: CASIA1/98/098_1_1.jpg   \n",
            "  inflating: CASIA1/98/098_1_2.jpg   \n",
            "  inflating: CASIA1/98/098_1_3.jpg   \n",
            "  inflating: CASIA1/98/098_2_1.jpg   \n",
            "  inflating: CASIA1/98/098_2_2.jpg   \n",
            "  inflating: CASIA1/98/098_2_3.jpg   \n",
            "  inflating: CASIA1/98/098_2_4.jpg   \n",
            "   creating: CASIA1/99/\n",
            "  inflating: CASIA1/99/099_1_1.jpg   \n",
            "  inflating: CASIA1/99/099_1_2.jpg   \n",
            "  inflating: CASIA1/99/099_1_3.jpg   \n",
            "  inflating: CASIA1/99/099_2_1.jpg   \n",
            "  inflating: CASIA1/99/099_2_2.jpg   \n",
            "  inflating: CASIA1/99/099_2_3.jpg   \n",
            "  inflating: CASIA1/99/099_2_4.jpg   \n",
            "  inflating: CASIA1/labels_test.json  \n",
            "  inflating: CASIA1/labels_train.json  \n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (0.22.2.post1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.4.58 qudida-0.0.4\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWhSxnlbup7I"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "import json \n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JHGxRtIvFnt"
      },
      "source": [
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, root, transform, train=True):\n",
        "        root = Path(root)\n",
        "        labels_file = root / 'labels_{}.json'.format('train' if train else 'test')\n",
        "        labels = json.load(labels_file.open('r'))\n",
        "        self.filenames = list(labels.keys())\n",
        "        self.labels = [labels[f] for f in self.filenames]\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "    \n",
        "    def load_image(self, filepath):\n",
        "\n",
        "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        # Augment an image\n",
        "        transformed = self.transform(image=image, keypoints=[])\n",
        "        transformed_image = transformed[\"image\"]\n",
        "        transformed_image = cv2.cvtColor(transformed_image,cv2.COLOR_RGB2GRAY)\n",
        "        transformed_image = torch.tensor(transformed_image/256, dtype=torch.float32)\n",
        "        return transformed_image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = (self.root / self.filenames[idx]).__str__()\n",
        "        label = self.labels[idx]\n",
        "        x, y, r, x_o, y_o,  r_o = label\n",
        "\n",
        "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        # Augment an image\n",
        "        transformed = self.transform(image=image, keypoints=[(x, y, r), (x_o, y_o, r_o)])\n",
        "        transformed_image = transformed[\"image\"]\n",
        "        [(x, y, r), (x_o, y_o, r_o)] = transformed['keypoints']\n",
        "        height, width, *_ = transformed_image.shape\n",
        "\n",
        "        transformed_image = cv2.cvtColor(transformed_image,cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        transformed_image = torch.tensor(transformed_image/256, dtype=torch.float32)\n",
        "\n",
        "        # transform\n",
        "        # image = torch.tensor(np.array(image) / 255, dtype=torch.float32)\n",
        "        \n",
        "        label = x/width, y/width, r/width, x_o/width, y_o/width, r_o/width\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        return (transformed_image, label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "AchUe2BLxZo2",
        "outputId": "5def680e-820d-45d4-93a2-fa372465f87f"
      },
      "source": [
        "train_transform = A.Compose([                       \n",
        "    # A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=(-0.0625, 0.0625), scale_limit=(-0.1, 0.1), rotate_limit=45),\n",
        "    A.RandomCrop(width=256, height=256),\n",
        "    A.Resize(height=64, width=64),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.RandomRain(),\n",
        "    # A.RandomSunFlare(),\n",
        "], keypoint_params=A.KeypointParams(format=\"xys\"))\n",
        "\n",
        "test_transform = A.Compose([                       \n",
        "    # A.HorizontalFlip(p=0.5),\n",
        "    # A.ShiftScaleRotate(shift_limit=(-0.0625, 0.0625), scale_limit=(-0.1, 0.1), rotate_limit=45),\n",
        "    A.RandomCrop(width=256, height=256),\n",
        "    A.Resize(height=64, width=64),\n",
        "    # A.RandomBrightnessContrast(p=0.2),\n",
        "    # A.RandomRain(),\n",
        "    # A.RandomSunFlare(),\n",
        "], keypoint_params=A.KeypointParams(format=\"xys\"))\n",
        "\n",
        "\n",
        "\n",
        "trainset = IrisDataset('CASIA1', transform=train_transform, train=True)\n",
        "testset = IrisDataset('CASIA1', transform=test_transform, train=False)\n",
        "print('len trainset:', len(trainset))\n",
        "print('len testset:', len(testset))\n",
        "image, labels = trainset[0]\n",
        "image = image.numpy() * 256\n",
        "x, y, r, x_o, y_o, r_o = labels\n",
        "# print(labels)\n",
        "h, w = image.shape\n",
        "image = cv2.circle(image, (int(x*w),int(y*w)), int(r*w), (255,), 1)\n",
        "image = cv2.circle(image, (int(x_o*w),int(y_o*w)), int(r_o*w), (255,), 1)\n",
        "cv2_imshow(image)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len trainset: 588\n",
            "len testset: 168\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B811750D0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFfNSrDU7DV8"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class YanNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        resnet18 = models.resnet18()\n",
        "        resnet18.fc = nn.Linear(resnet18.fc.in_features, 6)\n",
        "        self.resnet18 = resnet18\n",
        "    \n",
        "    def forward(self, x):\n",
        "        assert x.ndim == 3\n",
        "        x = torch.unsqueeze(x, 1).expand(-1, 3, -1, -1)\n",
        "        x = self.resnet18(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# images, labels = next(iter(train_loader))\n",
        "# images = images.to('cuda')\n",
        "# model = YanNet().cuda()\n",
        "# outputs = model(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAweLTWLOgNu",
        "outputId": "6d5a0821-2589-460c-e176-694761475603"
      },
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = YanNet().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.01, momentum=0.9)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "criterion = nn.SmoothL1Loss(beta=0.1)\n",
        "# criterion = nn.L1Loss()\n",
        "\n",
        "\n",
        "trainer = create_supervised_trainer(model, optimizer, criterion, device='cuda')\n",
        "\n",
        "val_metrics = {\n",
        "    \"mse\": Loss(criterion)\n",
        "}\n",
        "evaluator = create_supervised_evaluator(model, metrics=val_metrics, device='cuda')\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED(every=1))\n",
        "def log_training_loss(trainer):\n",
        "    print(f\"Epoch[{trainer.state.epoch}] Loss: {trainer.state.output:.4f}\")\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_results(trainer):\n",
        "    evaluator.run(train_loader)\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(f\"Training Results - Epoch: {trainer.state.epoch}  Avg loss: {metrics['mse']:.4f}\")\n",
        "    scheduler.step()\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results(trainer):\n",
        "    evaluator.run(val_loader)\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(f\"Validation Results - Epoch: {trainer.state.epoch}  Avg loss: {metrics['mse']:.4f}\")\n",
        "\n",
        "trainer.run(train_loader, max_epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch[1] Loss: 0.0913\n",
            "Epoch[1] Loss: 0.0742\n",
            "Epoch[1] Loss: 0.0516\n",
            "Epoch[1] Loss: 0.0297\n",
            "Epoch[1] Loss: 0.0363\n",
            "Epoch[1] Loss: 0.0392\n",
            "Epoch[1] Loss: 0.0480\n",
            "Epoch[1] Loss: 0.0418\n",
            "Epoch[1] Loss: 0.0405\n",
            "Epoch[1] Loss: 0.0364\n",
            "Epoch[1] Loss: 0.0383\n",
            "Epoch[1] Loss: 0.0416\n",
            "Epoch[1] Loss: 0.0333\n",
            "Epoch[1] Loss: 0.0315\n",
            "Epoch[1] Loss: 0.0364\n",
            "Epoch[1] Loss: 0.0392\n",
            "Epoch[1] Loss: 0.0314\n",
            "Epoch[1] Loss: 0.0278\n",
            "Epoch[1] Loss: 0.0268\n",
            "Training Results - Epoch: 1  Avg loss: 0.0291\n",
            "Validation Results - Epoch: 1  Avg loss: 0.0272\n",
            "Epoch[2] Loss: 0.0262\n",
            "Epoch[2] Loss: 0.0247\n",
            "Epoch[2] Loss: 0.0218\n",
            "Epoch[2] Loss: 0.0222\n",
            "Epoch[2] Loss: 0.0171\n",
            "Epoch[2] Loss: 0.0270\n",
            "Epoch[2] Loss: 0.0207\n",
            "Epoch[2] Loss: 0.0251\n",
            "Epoch[2] Loss: 0.0176\n",
            "Epoch[2] Loss: 0.0219\n",
            "Epoch[2] Loss: 0.0217\n",
            "Epoch[2] Loss: 0.0212\n",
            "Epoch[2] Loss: 0.0237\n",
            "Epoch[2] Loss: 0.0173\n",
            "Epoch[2] Loss: 0.0187\n",
            "Epoch[2] Loss: 0.0194\n",
            "Epoch[2] Loss: 0.0155\n",
            "Epoch[2] Loss: 0.0194\n",
            "Epoch[2] Loss: 0.0199\n",
            "Training Results - Epoch: 2  Avg loss: 0.0267\n",
            "Validation Results - Epoch: 2  Avg loss: 0.0308\n",
            "Epoch[3] Loss: 0.0224\n",
            "Epoch[3] Loss: 0.0186\n",
            "Epoch[3] Loss: 0.0137\n",
            "Epoch[3] Loss: 0.0146\n",
            "Epoch[3] Loss: 0.0188\n",
            "Epoch[3] Loss: 0.0207\n",
            "Epoch[3] Loss: 0.0184\n",
            "Epoch[3] Loss: 0.0171\n",
            "Epoch[3] Loss: 0.0214\n",
            "Epoch[3] Loss: 0.0116\n",
            "Epoch[3] Loss: 0.0157\n",
            "Epoch[3] Loss: 0.0170\n",
            "Epoch[3] Loss: 0.0155\n",
            "Epoch[3] Loss: 0.0205\n",
            "Epoch[3] Loss: 0.0166\n",
            "Epoch[3] Loss: 0.0115\n",
            "Epoch[3] Loss: 0.0171\n",
            "Epoch[3] Loss: 0.0149\n",
            "Epoch[3] Loss: 0.0167\n",
            "Training Results - Epoch: 3  Avg loss: 0.0149\n",
            "Validation Results - Epoch: 3  Avg loss: 0.0177\n",
            "Epoch[4] Loss: 0.0149\n",
            "Epoch[4] Loss: 0.0145\n",
            "Epoch[4] Loss: 0.0137\n",
            "Epoch[4] Loss: 0.0189\n",
            "Epoch[4] Loss: 0.0136\n",
            "Epoch[4] Loss: 0.0193\n",
            "Epoch[4] Loss: 0.0129\n",
            "Epoch[4] Loss: 0.0174\n",
            "Epoch[4] Loss: 0.0177\n",
            "Epoch[4] Loss: 0.0169\n",
            "Epoch[4] Loss: 0.0138\n",
            "Epoch[4] Loss: 0.0138\n",
            "Epoch[4] Loss: 0.0139\n",
            "Epoch[4] Loss: 0.0153\n",
            "Epoch[4] Loss: 0.0185\n",
            "Epoch[4] Loss: 0.0123\n",
            "Epoch[4] Loss: 0.0140\n",
            "Epoch[4] Loss: 0.0136\n",
            "Epoch[4] Loss: 0.0180\n",
            "Training Results - Epoch: 4  Avg loss: 0.0141\n",
            "Validation Results - Epoch: 4  Avg loss: 0.0178\n",
            "Epoch[5] Loss: 0.0133\n",
            "Epoch[5] Loss: 0.0158\n",
            "Epoch[5] Loss: 0.0169\n",
            "Epoch[5] Loss: 0.0163\n",
            "Epoch[5] Loss: 0.0150\n",
            "Epoch[5] Loss: 0.0150\n",
            "Epoch[5] Loss: 0.0122\n",
            "Epoch[5] Loss: 0.0119\n",
            "Epoch[5] Loss: 0.0103\n",
            "Epoch[5] Loss: 0.0150\n",
            "Epoch[5] Loss: 0.0138\n",
            "Epoch[5] Loss: 0.0126\n",
            "Epoch[5] Loss: 0.0148\n",
            "Epoch[5] Loss: 0.0146\n",
            "Epoch[5] Loss: 0.0120\n",
            "Epoch[5] Loss: 0.0122\n",
            "Epoch[5] Loss: 0.0158\n",
            "Epoch[5] Loss: 0.0106\n",
            "Epoch[5] Loss: 0.0096\n",
            "Training Results - Epoch: 5  Avg loss: 0.0134\n",
            "Validation Results - Epoch: 5  Avg loss: 0.0152\n",
            "Epoch[6] Loss: 0.0082\n",
            "Epoch[6] Loss: 0.0130\n",
            "Epoch[6] Loss: 0.0128\n",
            "Epoch[6] Loss: 0.0135\n",
            "Epoch[6] Loss: 0.0126\n",
            "Epoch[6] Loss: 0.0122\n",
            "Epoch[6] Loss: 0.0104\n",
            "Epoch[6] Loss: 0.0146\n",
            "Epoch[6] Loss: 0.0100\n",
            "Epoch[6] Loss: 0.0127\n",
            "Epoch[6] Loss: 0.0127\n",
            "Epoch[6] Loss: 0.0093\n",
            "Epoch[6] Loss: 0.0151\n",
            "Epoch[6] Loss: 0.0123\n",
            "Epoch[6] Loss: 0.0152\n",
            "Epoch[6] Loss: 0.0108\n",
            "Epoch[6] Loss: 0.0125\n",
            "Epoch[6] Loss: 0.0119\n",
            "Epoch[6] Loss: 0.0141\n",
            "Training Results - Epoch: 6  Avg loss: 0.0116\n",
            "Validation Results - Epoch: 6  Avg loss: 0.0133\n",
            "Epoch[7] Loss: 0.0103\n",
            "Epoch[7] Loss: 0.0072\n",
            "Epoch[7] Loss: 0.0112\n",
            "Epoch[7] Loss: 0.0099\n",
            "Epoch[7] Loss: 0.0143\n",
            "Epoch[7] Loss: 0.0109\n",
            "Epoch[7] Loss: 0.0163\n",
            "Epoch[7] Loss: 0.0128\n",
            "Epoch[7] Loss: 0.0097\n",
            "Epoch[7] Loss: 0.0116\n",
            "Epoch[7] Loss: 0.0172\n",
            "Epoch[7] Loss: 0.0100\n",
            "Epoch[7] Loss: 0.0108\n",
            "Epoch[7] Loss: 0.0095\n",
            "Epoch[7] Loss: 0.0092\n",
            "Epoch[7] Loss: 0.0110\n",
            "Epoch[7] Loss: 0.0114\n",
            "Epoch[7] Loss: 0.0122\n",
            "Epoch[7] Loss: 0.0131\n",
            "Training Results - Epoch: 7  Avg loss: 0.0113\n",
            "Validation Results - Epoch: 7  Avg loss: 0.0142\n",
            "Epoch[8] Loss: 0.0122\n",
            "Epoch[8] Loss: 0.0119\n",
            "Epoch[8] Loss: 0.0130\n",
            "Epoch[8] Loss: 0.0092\n",
            "Epoch[8] Loss: 0.0111\n",
            "Epoch[8] Loss: 0.0089\n",
            "Epoch[8] Loss: 0.0098\n",
            "Epoch[8] Loss: 0.0151\n",
            "Epoch[8] Loss: 0.0111\n",
            "Epoch[8] Loss: 0.0107\n",
            "Epoch[8] Loss: 0.0132\n",
            "Epoch[8] Loss: 0.0092\n",
            "Epoch[8] Loss: 0.0108\n",
            "Epoch[8] Loss: 0.0094\n",
            "Epoch[8] Loss: 0.0117\n",
            "Epoch[8] Loss: 0.0072\n",
            "Epoch[8] Loss: 0.0090\n",
            "Epoch[8] Loss: 0.0094\n",
            "Epoch[8] Loss: 0.0070\n",
            "Training Results - Epoch: 8  Avg loss: 0.0099\n",
            "Validation Results - Epoch: 8  Avg loss: 0.0124\n",
            "Epoch[9] Loss: 0.0077\n",
            "Epoch[9] Loss: 0.0106\n",
            "Epoch[9] Loss: 0.0083\n",
            "Epoch[9] Loss: 0.0085\n",
            "Epoch[9] Loss: 0.0090\n",
            "Epoch[9] Loss: 0.0110\n",
            "Epoch[9] Loss: 0.0099\n",
            "Epoch[9] Loss: 0.0084\n",
            "Epoch[9] Loss: 0.0103\n",
            "Epoch[9] Loss: 0.0076\n",
            "Epoch[9] Loss: 0.0102\n",
            "Epoch[9] Loss: 0.0103\n",
            "Epoch[9] Loss: 0.0121\n",
            "Epoch[9] Loss: 0.0123\n",
            "Epoch[9] Loss: 0.0080\n",
            "Epoch[9] Loss: 0.0121\n",
            "Epoch[9] Loss: 0.0082\n",
            "Epoch[9] Loss: 0.0137\n",
            "Epoch[9] Loss: 0.0103\n",
            "Training Results - Epoch: 9  Avg loss: 0.0095\n",
            "Validation Results - Epoch: 9  Avg loss: 0.0125\n",
            "Epoch[10] Loss: 0.0101\n",
            "Epoch[10] Loss: 0.0107\n",
            "Epoch[10] Loss: 0.0089\n",
            "Epoch[10] Loss: 0.0101\n",
            "Epoch[10] Loss: 0.0077\n",
            "Epoch[10] Loss: 0.0101\n",
            "Epoch[10] Loss: 0.0079\n",
            "Epoch[10] Loss: 0.0107\n",
            "Epoch[10] Loss: 0.0100\n",
            "Epoch[10] Loss: 0.0098\n",
            "Epoch[10] Loss: 0.0097\n",
            "Epoch[10] Loss: 0.0088\n",
            "Epoch[10] Loss: 0.0092\n",
            "Epoch[10] Loss: 0.0063\n",
            "Epoch[10] Loss: 0.0078\n",
            "Epoch[10] Loss: 0.0100\n",
            "Epoch[10] Loss: 0.0089\n",
            "Epoch[10] Loss: 0.0081\n",
            "Epoch[10] Loss: 0.0071\n",
            "Training Results - Epoch: 10  Avg loss: 0.0090\n",
            "Validation Results - Epoch: 10  Avg loss: 0.0103\n",
            "Epoch[11] Loss: 0.0083\n",
            "Epoch[11] Loss: 0.0085\n",
            "Epoch[11] Loss: 0.0098\n",
            "Epoch[11] Loss: 0.0109\n",
            "Epoch[11] Loss: 0.0096\n",
            "Epoch[11] Loss: 0.0077\n",
            "Epoch[11] Loss: 0.0082\n",
            "Epoch[11] Loss: 0.0081\n",
            "Epoch[11] Loss: 0.0086\n",
            "Epoch[11] Loss: 0.0090\n",
            "Epoch[11] Loss: 0.0100\n",
            "Epoch[11] Loss: 0.0082\n",
            "Epoch[11] Loss: 0.0142\n",
            "Epoch[11] Loss: 0.0079\n",
            "Epoch[11] Loss: 0.0095\n",
            "Epoch[11] Loss: 0.0097\n",
            "Epoch[11] Loss: 0.0075\n",
            "Epoch[11] Loss: 0.0134\n",
            "Epoch[11] Loss: 0.0116\n",
            "Training Results - Epoch: 11  Avg loss: 0.0081\n",
            "Validation Results - Epoch: 11  Avg loss: 0.0113\n",
            "Epoch[12] Loss: 0.0110\n",
            "Epoch[12] Loss: 0.0099\n",
            "Epoch[12] Loss: 0.0088\n",
            "Epoch[12] Loss: 0.0107\n",
            "Epoch[12] Loss: 0.0089\n",
            "Epoch[12] Loss: 0.0076\n",
            "Epoch[12] Loss: 0.0093\n",
            "Epoch[12] Loss: 0.0079\n",
            "Epoch[12] Loss: 0.0091\n",
            "Epoch[12] Loss: 0.0078\n",
            "Epoch[12] Loss: 0.0081\n",
            "Epoch[12] Loss: 0.0068\n",
            "Epoch[12] Loss: 0.0103\n",
            "Epoch[12] Loss: 0.0065\n",
            "Epoch[12] Loss: 0.0090\n",
            "Epoch[12] Loss: 0.0104\n",
            "Epoch[12] Loss: 0.0114\n",
            "Epoch[12] Loss: 0.0071\n",
            "Epoch[12] Loss: 0.0174\n",
            "Training Results - Epoch: 12  Avg loss: 0.0077\n",
            "Validation Results - Epoch: 12  Avg loss: 0.0104\n",
            "Epoch[13] Loss: 0.0083\n",
            "Epoch[13] Loss: 0.0079\n",
            "Epoch[13] Loss: 0.0094\n",
            "Epoch[13] Loss: 0.0088\n",
            "Epoch[13] Loss: 0.0112\n",
            "Epoch[13] Loss: 0.0078\n",
            "Epoch[13] Loss: 0.0073\n",
            "Epoch[13] Loss: 0.0075\n",
            "Epoch[13] Loss: 0.0074\n",
            "Epoch[13] Loss: 0.0090\n",
            "Epoch[13] Loss: 0.0085\n",
            "Epoch[13] Loss: 0.0079\n",
            "Epoch[13] Loss: 0.0078\n",
            "Epoch[13] Loss: 0.0084\n",
            "Epoch[13] Loss: 0.0085\n",
            "Epoch[13] Loss: 0.0076\n",
            "Epoch[13] Loss: 0.0103\n",
            "Epoch[13] Loss: 0.0062\n",
            "Epoch[13] Loss: 0.0120\n",
            "Training Results - Epoch: 13  Avg loss: 0.0082\n",
            "Validation Results - Epoch: 13  Avg loss: 0.0101\n",
            "Epoch[14] Loss: 0.0075\n",
            "Epoch[14] Loss: 0.0062\n",
            "Epoch[14] Loss: 0.0069\n",
            "Epoch[14] Loss: 0.0060\n",
            "Epoch[14] Loss: 0.0085\n",
            "Epoch[14] Loss: 0.0064\n",
            "Epoch[14] Loss: 0.0091\n",
            "Epoch[14] Loss: 0.0073\n",
            "Epoch[14] Loss: 0.0080\n",
            "Epoch[14] Loss: 0.0077\n",
            "Epoch[14] Loss: 0.0086\n",
            "Epoch[14] Loss: 0.0103\n",
            "Epoch[14] Loss: 0.0062\n",
            "Epoch[14] Loss: 0.0118\n",
            "Epoch[14] Loss: 0.0077\n",
            "Epoch[14] Loss: 0.0085\n",
            "Epoch[14] Loss: 0.0087\n",
            "Epoch[14] Loss: 0.0132\n",
            "Epoch[14] Loss: 0.0090\n",
            "Training Results - Epoch: 14  Avg loss: 0.0084\n",
            "Validation Results - Epoch: 14  Avg loss: 0.0097\n",
            "Epoch[15] Loss: 0.0072\n",
            "Epoch[15] Loss: 0.0093\n",
            "Epoch[15] Loss: 0.0074\n",
            "Epoch[15] Loss: 0.0084\n",
            "Epoch[15] Loss: 0.0078\n",
            "Epoch[15] Loss: 0.0089\n",
            "Epoch[15] Loss: 0.0078\n",
            "Epoch[15] Loss: 0.0062\n",
            "Epoch[15] Loss: 0.0094\n",
            "Epoch[15] Loss: 0.0097\n",
            "Epoch[15] Loss: 0.0099\n",
            "Epoch[15] Loss: 0.0081\n",
            "Epoch[15] Loss: 0.0086\n",
            "Epoch[15] Loss: 0.0087\n",
            "Epoch[15] Loss: 0.0087\n",
            "Epoch[15] Loss: 0.0069\n",
            "Epoch[15] Loss: 0.0108\n",
            "Epoch[15] Loss: 0.0082\n",
            "Epoch[15] Loss: 0.0098\n",
            "Training Results - Epoch: 15  Avg loss: 0.0077\n",
            "Validation Results - Epoch: 15  Avg loss: 0.0096\n",
            "Epoch[16] Loss: 0.0079\n",
            "Epoch[16] Loss: 0.0079\n",
            "Epoch[16] Loss: 0.0105\n",
            "Epoch[16] Loss: 0.0067\n",
            "Epoch[16] Loss: 0.0075\n",
            "Epoch[16] Loss: 0.0089\n",
            "Epoch[16] Loss: 0.0070\n",
            "Epoch[16] Loss: 0.0086\n",
            "Epoch[16] Loss: 0.0088\n",
            "Epoch[16] Loss: 0.0085\n",
            "Epoch[16] Loss: 0.0114\n",
            "Epoch[16] Loss: 0.0097\n",
            "Epoch[16] Loss: 0.0080\n",
            "Epoch[16] Loss: 0.0061\n",
            "Epoch[16] Loss: 0.0080\n",
            "Epoch[16] Loss: 0.0057\n",
            "Epoch[16] Loss: 0.0091\n",
            "Epoch[16] Loss: 0.0067\n",
            "Epoch[16] Loss: 0.0084\n",
            "Training Results - Epoch: 16  Avg loss: 0.0073\n",
            "Validation Results - Epoch: 16  Avg loss: 0.0094\n",
            "Epoch[17] Loss: 0.0103\n",
            "Epoch[17] Loss: 0.0100\n",
            "Epoch[17] Loss: 0.0086\n",
            "Epoch[17] Loss: 0.0069\n",
            "Epoch[17] Loss: 0.0087\n",
            "Epoch[17] Loss: 0.0062\n",
            "Epoch[17] Loss: 0.0058\n",
            "Epoch[17] Loss: 0.0096\n",
            "Epoch[17] Loss: 0.0064\n",
            "Epoch[17] Loss: 0.0093\n",
            "Epoch[17] Loss: 0.0089\n",
            "Epoch[17] Loss: 0.0114\n",
            "Epoch[17] Loss: 0.0074\n",
            "Epoch[17] Loss: 0.0080\n",
            "Epoch[17] Loss: 0.0053\n",
            "Epoch[17] Loss: 0.0068\n",
            "Epoch[17] Loss: 0.0092\n",
            "Epoch[17] Loss: 0.0072\n",
            "Epoch[17] Loss: 0.0087\n",
            "Training Results - Epoch: 17  Avg loss: 0.0076\n",
            "Validation Results - Epoch: 17  Avg loss: 0.0087\n",
            "Epoch[18] Loss: 0.0122\n",
            "Epoch[18] Loss: 0.0075\n",
            "Epoch[18] Loss: 0.0079\n",
            "Epoch[18] Loss: 0.0080\n",
            "Epoch[18] Loss: 0.0095\n",
            "Epoch[18] Loss: 0.0078\n",
            "Epoch[18] Loss: 0.0096\n",
            "Epoch[18] Loss: 0.0077\n",
            "Epoch[18] Loss: 0.0061\n",
            "Epoch[18] Loss: 0.0063\n",
            "Epoch[18] Loss: 0.0092\n",
            "Epoch[18] Loss: 0.0109\n",
            "Epoch[18] Loss: 0.0086\n",
            "Epoch[18] Loss: 0.0076\n",
            "Epoch[18] Loss: 0.0076\n",
            "Epoch[18] Loss: 0.0075\n",
            "Epoch[18] Loss: 0.0062\n",
            "Epoch[18] Loss: 0.0077\n",
            "Epoch[18] Loss: 0.0133\n",
            "Training Results - Epoch: 18  Avg loss: 0.0079\n",
            "Validation Results - Epoch: 18  Avg loss: 0.0098\n",
            "Epoch[19] Loss: 0.0087\n",
            "Epoch[19] Loss: 0.0072\n",
            "Epoch[19] Loss: 0.0072\n",
            "Epoch[19] Loss: 0.0079\n",
            "Epoch[19] Loss: 0.0086\n",
            "Epoch[19] Loss: 0.0058\n",
            "Epoch[19] Loss: 0.0059\n",
            "Epoch[19] Loss: 0.0060\n",
            "Epoch[19] Loss: 0.0111\n",
            "Epoch[19] Loss: 0.0075\n",
            "Epoch[19] Loss: 0.0054\n",
            "Epoch[19] Loss: 0.0063\n",
            "Epoch[19] Loss: 0.0106\n",
            "Epoch[19] Loss: 0.0087\n",
            "Epoch[19] Loss: 0.0067\n",
            "Epoch[19] Loss: 0.0076\n",
            "Epoch[19] Loss: 0.0054\n",
            "Epoch[19] Loss: 0.0084\n",
            "Epoch[19] Loss: 0.0119\n",
            "Training Results - Epoch: 19  Avg loss: 0.0070\n",
            "Validation Results - Epoch: 19  Avg loss: 0.0085\n",
            "Epoch[20] Loss: 0.0098\n",
            "Epoch[20] Loss: 0.0092\n",
            "Epoch[20] Loss: 0.0096\n",
            "Epoch[20] Loss: 0.0085\n",
            "Epoch[20] Loss: 0.0105\n",
            "Epoch[20] Loss: 0.0060\n",
            "Epoch[20] Loss: 0.0157\n",
            "Epoch[20] Loss: 0.0066\n",
            "Epoch[20] Loss: 0.0067\n",
            "Epoch[20] Loss: 0.0078\n",
            "Epoch[20] Loss: 0.0075\n",
            "Epoch[20] Loss: 0.0055\n",
            "Epoch[20] Loss: 0.0078\n",
            "Epoch[20] Loss: 0.0091\n",
            "Epoch[20] Loss: 0.0073\n",
            "Epoch[20] Loss: 0.0096\n",
            "Epoch[20] Loss: 0.0057\n",
            "Epoch[20] Loss: 0.0076\n",
            "Epoch[20] Loss: 0.0050\n",
            "Training Results - Epoch: 20  Avg loss: 0.0071\n",
            "Validation Results - Epoch: 20  Avg loss: 0.0083\n",
            "Epoch[21] Loss: 0.0077\n",
            "Epoch[21] Loss: 0.0080\n",
            "Epoch[21] Loss: 0.0061\n",
            "Epoch[21] Loss: 0.0072\n",
            "Epoch[21] Loss: 0.0089\n",
            "Epoch[21] Loss: 0.0065\n",
            "Epoch[21] Loss: 0.0077\n",
            "Epoch[21] Loss: 0.0068\n",
            "Epoch[21] Loss: 0.0070\n",
            "Epoch[21] Loss: 0.0067\n",
            "Epoch[21] Loss: 0.0071\n",
            "Epoch[21] Loss: 0.0064\n",
            "Epoch[21] Loss: 0.0074\n",
            "Epoch[21] Loss: 0.0084\n",
            "Epoch[21] Loss: 0.0074\n",
            "Epoch[21] Loss: 0.0057\n",
            "Epoch[21] Loss: 0.0055\n",
            "Epoch[21] Loss: 0.0062\n",
            "Epoch[21] Loss: 0.0085\n",
            "Training Results - Epoch: 21  Avg loss: 0.0066\n",
            "Validation Results - Epoch: 21  Avg loss: 0.0089\n",
            "Epoch[22] Loss: 0.0094\n",
            "Epoch[22] Loss: 0.0088\n",
            "Epoch[22] Loss: 0.0060\n",
            "Epoch[22] Loss: 0.0071\n",
            "Epoch[22] Loss: 0.0080\n",
            "Epoch[22] Loss: 0.0054\n",
            "Epoch[22] Loss: 0.0058\n",
            "Epoch[22] Loss: 0.0082\n",
            "Epoch[22] Loss: 0.0066\n",
            "Epoch[22] Loss: 0.0076\n",
            "Epoch[22] Loss: 0.0056\n",
            "Epoch[22] Loss: 0.0068\n",
            "Epoch[22] Loss: 0.0095\n",
            "Epoch[22] Loss: 0.0090\n",
            "Epoch[22] Loss: 0.0068\n",
            "Epoch[22] Loss: 0.0081\n",
            "Epoch[22] Loss: 0.0074\n",
            "Epoch[22] Loss: 0.0078\n",
            "Epoch[22] Loss: 0.0075\n",
            "Training Results - Epoch: 22  Avg loss: 0.0069\n",
            "Validation Results - Epoch: 22  Avg loss: 0.0089\n",
            "Epoch[23] Loss: 0.0057\n",
            "Epoch[23] Loss: 0.0065\n",
            "Epoch[23] Loss: 0.0067\n",
            "Epoch[23] Loss: 0.0092\n",
            "Epoch[23] Loss: 0.0111\n",
            "Epoch[23] Loss: 0.0080\n",
            "Epoch[23] Loss: 0.0063\n",
            "Epoch[23] Loss: 0.0094\n",
            "Epoch[23] Loss: 0.0086\n",
            "Epoch[23] Loss: 0.0074\n",
            "Epoch[23] Loss: 0.0064\n",
            "Epoch[23] Loss: 0.0063\n",
            "Epoch[23] Loss: 0.0067\n",
            "Epoch[23] Loss: 0.0064\n",
            "Epoch[23] Loss: 0.0089\n",
            "Epoch[23] Loss: 0.0052\n",
            "Epoch[23] Loss: 0.0068\n",
            "Epoch[23] Loss: 0.0065\n",
            "Epoch[23] Loss: 0.0092\n",
            "Training Results - Epoch: 23  Avg loss: 0.0069\n",
            "Validation Results - Epoch: 23  Avg loss: 0.0083\n",
            "Epoch[24] Loss: 0.0072\n",
            "Epoch[24] Loss: 0.0073\n",
            "Epoch[24] Loss: 0.0063\n",
            "Epoch[24] Loss: 0.0092\n",
            "Epoch[24] Loss: 0.0050\n",
            "Epoch[24] Loss: 0.0092\n",
            "Epoch[24] Loss: 0.0091\n",
            "Epoch[24] Loss: 0.0058\n",
            "Epoch[24] Loss: 0.0072\n",
            "Epoch[24] Loss: 0.0096\n",
            "Epoch[24] Loss: 0.0078\n",
            "Epoch[24] Loss: 0.0061\n",
            "Epoch[24] Loss: 0.0066\n",
            "Epoch[24] Loss: 0.0077\n",
            "Epoch[24] Loss: 0.0065\n",
            "Epoch[24] Loss: 0.0057\n",
            "Epoch[24] Loss: 0.0059\n",
            "Epoch[24] Loss: 0.0055\n",
            "Epoch[24] Loss: 0.0073\n",
            "Training Results - Epoch: 24  Avg loss: 0.0064\n",
            "Validation Results - Epoch: 24  Avg loss: 0.0091\n",
            "Epoch[25] Loss: 0.0093\n",
            "Epoch[25] Loss: 0.0071\n",
            "Epoch[25] Loss: 0.0072\n",
            "Epoch[25] Loss: 0.0068\n",
            "Epoch[25] Loss: 0.0078\n",
            "Epoch[25] Loss: 0.0094\n",
            "Epoch[25] Loss: 0.0067\n",
            "Epoch[25] Loss: 0.0064\n",
            "Epoch[25] Loss: 0.0059\n",
            "Epoch[25] Loss: 0.0092\n",
            "Epoch[25] Loss: 0.0080\n",
            "Epoch[25] Loss: 0.0070\n",
            "Epoch[25] Loss: 0.0054\n",
            "Epoch[25] Loss: 0.0079\n",
            "Epoch[25] Loss: 0.0114\n",
            "Epoch[25] Loss: 0.0099\n",
            "Epoch[25] Loss: 0.0062\n",
            "Epoch[25] Loss: 0.0085\n",
            "Epoch[25] Loss: 0.0094\n",
            "Training Results - Epoch: 25  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 25  Avg loss: 0.0077\n",
            "Epoch[26] Loss: 0.0076\n",
            "Epoch[26] Loss: 0.0048\n",
            "Epoch[26] Loss: 0.0055\n",
            "Epoch[26] Loss: 0.0079\n",
            "Epoch[26] Loss: 0.0077\n",
            "Epoch[26] Loss: 0.0058\n",
            "Epoch[26] Loss: 0.0049\n",
            "Epoch[26] Loss: 0.0067\n",
            "Epoch[26] Loss: 0.0068\n",
            "Epoch[26] Loss: 0.0064\n",
            "Epoch[26] Loss: 0.0066\n",
            "Epoch[26] Loss: 0.0077\n",
            "Epoch[26] Loss: 0.0054\n",
            "Epoch[26] Loss: 0.0074\n",
            "Epoch[26] Loss: 0.0085\n",
            "Epoch[26] Loss: 0.0062\n",
            "Epoch[26] Loss: 0.0069\n",
            "Epoch[26] Loss: 0.0103\n",
            "Epoch[26] Loss: 0.0105\n",
            "Training Results - Epoch: 26  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 26  Avg loss: 0.0082\n",
            "Epoch[27] Loss: 0.0074\n",
            "Epoch[27] Loss: 0.0072\n",
            "Epoch[27] Loss: 0.0056\n",
            "Epoch[27] Loss: 0.0086\n",
            "Epoch[27] Loss: 0.0068\n",
            "Epoch[27] Loss: 0.0076\n",
            "Epoch[27] Loss: 0.0056\n",
            "Epoch[27] Loss: 0.0058\n",
            "Epoch[27] Loss: 0.0099\n",
            "Epoch[27] Loss: 0.0065\n",
            "Epoch[27] Loss: 0.0049\n",
            "Epoch[27] Loss: 0.0087\n",
            "Epoch[27] Loss: 0.0063\n",
            "Epoch[27] Loss: 0.0083\n",
            "Epoch[27] Loss: 0.0064\n",
            "Epoch[27] Loss: 0.0052\n",
            "Epoch[27] Loss: 0.0072\n",
            "Epoch[27] Loss: 0.0093\n",
            "Epoch[27] Loss: 0.0144\n",
            "Training Results - Epoch: 27  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 27  Avg loss: 0.0083\n",
            "Epoch[28] Loss: 0.0104\n",
            "Epoch[28] Loss: 0.0071\n",
            "Epoch[28] Loss: 0.0071\n",
            "Epoch[28] Loss: 0.0052\n",
            "Epoch[28] Loss: 0.0086\n",
            "Epoch[28] Loss: 0.0080\n",
            "Epoch[28] Loss: 0.0062\n",
            "Epoch[28] Loss: 0.0074\n",
            "Epoch[28] Loss: 0.0067\n",
            "Epoch[28] Loss: 0.0047\n",
            "Epoch[28] Loss: 0.0073\n",
            "Epoch[28] Loss: 0.0067\n",
            "Epoch[28] Loss: 0.0066\n",
            "Epoch[28] Loss: 0.0085\n",
            "Epoch[28] Loss: 0.0059\n",
            "Epoch[28] Loss: 0.0069\n",
            "Epoch[28] Loss: 0.0063\n",
            "Epoch[28] Loss: 0.0072\n",
            "Epoch[28] Loss: 0.0113\n",
            "Training Results - Epoch: 28  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 28  Avg loss: 0.0082\n",
            "Epoch[29] Loss: 0.0043\n",
            "Epoch[29] Loss: 0.0076\n",
            "Epoch[29] Loss: 0.0064\n",
            "Epoch[29] Loss: 0.0062\n",
            "Epoch[29] Loss: 0.0058\n",
            "Epoch[29] Loss: 0.0059\n",
            "Epoch[29] Loss: 0.0060\n",
            "Epoch[29] Loss: 0.0072\n",
            "Epoch[29] Loss: 0.0074\n",
            "Epoch[29] Loss: 0.0101\n",
            "Epoch[29] Loss: 0.0066\n",
            "Epoch[29] Loss: 0.0062\n",
            "Epoch[29] Loss: 0.0059\n",
            "Epoch[29] Loss: 0.0066\n",
            "Epoch[29] Loss: 0.0068\n",
            "Epoch[29] Loss: 0.0055\n",
            "Epoch[29] Loss: 0.0097\n",
            "Epoch[29] Loss: 0.0086\n",
            "Epoch[29] Loss: 0.0076\n",
            "Training Results - Epoch: 29  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 29  Avg loss: 0.0081\n",
            "Epoch[30] Loss: 0.0054\n",
            "Epoch[30] Loss: 0.0068\n",
            "Epoch[30] Loss: 0.0070\n",
            "Epoch[30] Loss: 0.0058\n",
            "Epoch[30] Loss: 0.0073\n",
            "Epoch[30] Loss: 0.0065\n",
            "Epoch[30] Loss: 0.0062\n",
            "Epoch[30] Loss: 0.0065\n",
            "Epoch[30] Loss: 0.0084\n",
            "Epoch[30] Loss: 0.0055\n",
            "Epoch[30] Loss: 0.0057\n",
            "Epoch[30] Loss: 0.0063\n",
            "Epoch[30] Loss: 0.0064\n",
            "Epoch[30] Loss: 0.0074\n",
            "Epoch[30] Loss: 0.0065\n",
            "Epoch[30] Loss: 0.0068\n",
            "Epoch[30] Loss: 0.0069\n",
            "Epoch[30] Loss: 0.0089\n",
            "Epoch[30] Loss: 0.0096\n",
            "Training Results - Epoch: 30  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 30  Avg loss: 0.0085\n",
            "Epoch[31] Loss: 0.0062\n",
            "Epoch[31] Loss: 0.0075\n",
            "Epoch[31] Loss: 0.0061\n",
            "Epoch[31] Loss: 0.0101\n",
            "Epoch[31] Loss: 0.0063\n",
            "Epoch[31] Loss: 0.0065\n",
            "Epoch[31] Loss: 0.0062\n",
            "Epoch[31] Loss: 0.0043\n",
            "Epoch[31] Loss: 0.0059\n",
            "Epoch[31] Loss: 0.0064\n",
            "Epoch[31] Loss: 0.0075\n",
            "Epoch[31] Loss: 0.0067\n",
            "Epoch[31] Loss: 0.0060\n",
            "Epoch[31] Loss: 0.0068\n",
            "Epoch[31] Loss: 0.0068\n",
            "Epoch[31] Loss: 0.0058\n",
            "Epoch[31] Loss: 0.0072\n",
            "Epoch[31] Loss: 0.0073\n",
            "Epoch[31] Loss: 0.0068\n",
            "Training Results - Epoch: 31  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 31  Avg loss: 0.0077\n",
            "Epoch[32] Loss: 0.0094\n",
            "Epoch[32] Loss: 0.0071\n",
            "Epoch[32] Loss: 0.0053\n",
            "Epoch[32] Loss: 0.0053\n",
            "Epoch[32] Loss: 0.0111\n",
            "Epoch[32] Loss: 0.0070\n",
            "Epoch[32] Loss: 0.0074\n",
            "Epoch[32] Loss: 0.0074\n",
            "Epoch[32] Loss: 0.0070\n",
            "Epoch[32] Loss: 0.0053\n",
            "Epoch[32] Loss: 0.0046\n",
            "Epoch[32] Loss: 0.0089\n",
            "Epoch[32] Loss: 0.0089\n",
            "Epoch[32] Loss: 0.0075\n",
            "Epoch[32] Loss: 0.0055\n",
            "Epoch[32] Loss: 0.0077\n",
            "Epoch[32] Loss: 0.0078\n",
            "Epoch[32] Loss: 0.0101\n",
            "Epoch[32] Loss: 0.0099\n",
            "Training Results - Epoch: 32  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 32  Avg loss: 0.0078\n",
            "Epoch[33] Loss: 0.0066\n",
            "Epoch[33] Loss: 0.0061\n",
            "Epoch[33] Loss: 0.0068\n",
            "Epoch[33] Loss: 0.0069\n",
            "Epoch[33] Loss: 0.0059\n",
            "Epoch[33] Loss: 0.0072\n",
            "Epoch[33] Loss: 0.0057\n",
            "Epoch[33] Loss: 0.0071\n",
            "Epoch[33] Loss: 0.0057\n",
            "Epoch[33] Loss: 0.0078\n",
            "Epoch[33] Loss: 0.0072\n",
            "Epoch[33] Loss: 0.0079\n",
            "Epoch[33] Loss: 0.0094\n",
            "Epoch[33] Loss: 0.0071\n",
            "Epoch[33] Loss: 0.0052\n",
            "Epoch[33] Loss: 0.0062\n",
            "Epoch[33] Loss: 0.0071\n",
            "Epoch[33] Loss: 0.0062\n",
            "Epoch[33] Loss: 0.0091\n",
            "Training Results - Epoch: 33  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 33  Avg loss: 0.0078\n",
            "Epoch[34] Loss: 0.0057\n",
            "Epoch[34] Loss: 0.0065\n",
            "Epoch[34] Loss: 0.0085\n",
            "Epoch[34] Loss: 0.0078\n",
            "Epoch[34] Loss: 0.0058\n",
            "Epoch[34] Loss: 0.0081\n",
            "Epoch[34] Loss: 0.0082\n",
            "Epoch[34] Loss: 0.0066\n",
            "Epoch[34] Loss: 0.0047\n",
            "Epoch[34] Loss: 0.0058\n",
            "Epoch[34] Loss: 0.0098\n",
            "Epoch[34] Loss: 0.0100\n",
            "Epoch[34] Loss: 0.0064\n",
            "Epoch[34] Loss: 0.0059\n",
            "Epoch[34] Loss: 0.0064\n",
            "Epoch[34] Loss: 0.0060\n",
            "Epoch[34] Loss: 0.0086\n",
            "Epoch[34] Loss: 0.0101\n",
            "Epoch[34] Loss: 0.0079\n",
            "Training Results - Epoch: 34  Avg loss: 0.0068\n",
            "Validation Results - Epoch: 34  Avg loss: 0.0081\n",
            "Epoch[35] Loss: 0.0073\n",
            "Epoch[35] Loss: 0.0055\n",
            "Epoch[35] Loss: 0.0056\n",
            "Epoch[35] Loss: 0.0071\n",
            "Epoch[35] Loss: 0.0056\n",
            "Epoch[35] Loss: 0.0080\n",
            "Epoch[35] Loss: 0.0075\n",
            "Epoch[35] Loss: 0.0063\n",
            "Epoch[35] Loss: 0.0058\n",
            "Epoch[35] Loss: 0.0054\n",
            "Epoch[35] Loss: 0.0053\n",
            "Epoch[35] Loss: 0.0062\n",
            "Epoch[35] Loss: 0.0061\n",
            "Epoch[35] Loss: 0.0082\n",
            "Epoch[35] Loss: 0.0058\n",
            "Epoch[35] Loss: 0.0075\n",
            "Epoch[35] Loss: 0.0070\n",
            "Epoch[35] Loss: 0.0071\n",
            "Epoch[35] Loss: 0.0156\n",
            "Training Results - Epoch: 35  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 35  Avg loss: 0.0079\n",
            "Epoch[36] Loss: 0.0082\n",
            "Epoch[36] Loss: 0.0071\n",
            "Epoch[36] Loss: 0.0080\n",
            "Epoch[36] Loss: 0.0086\n",
            "Epoch[36] Loss: 0.0057\n",
            "Epoch[36] Loss: 0.0066\n",
            "Epoch[36] Loss: 0.0090\n",
            "Epoch[36] Loss: 0.0048\n",
            "Epoch[36] Loss: 0.0069\n",
            "Epoch[36] Loss: 0.0082\n",
            "Epoch[36] Loss: 0.0095\n",
            "Epoch[36] Loss: 0.0058\n",
            "Epoch[36] Loss: 0.0066\n",
            "Epoch[36] Loss: 0.0066\n",
            "Epoch[36] Loss: 0.0071\n",
            "Epoch[36] Loss: 0.0068\n",
            "Epoch[36] Loss: 0.0072\n",
            "Epoch[36] Loss: 0.0077\n",
            "Epoch[36] Loss: 0.0056\n",
            "Training Results - Epoch: 36  Avg loss: 0.0064\n",
            "Validation Results - Epoch: 36  Avg loss: 0.0078\n",
            "Epoch[37] Loss: 0.0064\n",
            "Epoch[37] Loss: 0.0053\n",
            "Epoch[37] Loss: 0.0052\n",
            "Epoch[37] Loss: 0.0060\n",
            "Epoch[37] Loss: 0.0068\n",
            "Epoch[37] Loss: 0.0057\n",
            "Epoch[37] Loss: 0.0073\n",
            "Epoch[37] Loss: 0.0064\n",
            "Epoch[37] Loss: 0.0067\n",
            "Epoch[37] Loss: 0.0093\n",
            "Epoch[37] Loss: 0.0071\n",
            "Epoch[37] Loss: 0.0061\n",
            "Epoch[37] Loss: 0.0091\n",
            "Epoch[37] Loss: 0.0054\n",
            "Epoch[37] Loss: 0.0061\n",
            "Epoch[37] Loss: 0.0072\n",
            "Epoch[37] Loss: 0.0082\n",
            "Epoch[37] Loss: 0.0064\n",
            "Epoch[37] Loss: 0.0065\n",
            "Training Results - Epoch: 37  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 37  Avg loss: 0.0075\n",
            "Epoch[38] Loss: 0.0079\n",
            "Epoch[38] Loss: 0.0061\n",
            "Epoch[38] Loss: 0.0068\n",
            "Epoch[38] Loss: 0.0049\n",
            "Epoch[38] Loss: 0.0067\n",
            "Epoch[38] Loss: 0.0066\n",
            "Epoch[38] Loss: 0.0074\n",
            "Epoch[38] Loss: 0.0090\n",
            "Epoch[38] Loss: 0.0058\n",
            "Epoch[38] Loss: 0.0059\n",
            "Epoch[38] Loss: 0.0063\n",
            "Epoch[38] Loss: 0.0071\n",
            "Epoch[38] Loss: 0.0069\n",
            "Epoch[38] Loss: 0.0067\n",
            "Epoch[38] Loss: 0.0064\n",
            "Epoch[38] Loss: 0.0071\n",
            "Epoch[38] Loss: 0.0077\n",
            "Epoch[38] Loss: 0.0066\n",
            "Epoch[38] Loss: 0.0093\n",
            "Training Results - Epoch: 38  Avg loss: 0.0064\n",
            "Validation Results - Epoch: 38  Avg loss: 0.0076\n",
            "Epoch[39] Loss: 0.0057\n",
            "Epoch[39] Loss: 0.0060\n",
            "Epoch[39] Loss: 0.0072\n",
            "Epoch[39] Loss: 0.0080\n",
            "Epoch[39] Loss: 0.0074\n",
            "Epoch[39] Loss: 0.0058\n",
            "Epoch[39] Loss: 0.0055\n",
            "Epoch[39] Loss: 0.0065\n",
            "Epoch[39] Loss: 0.0084\n",
            "Epoch[39] Loss: 0.0080\n",
            "Epoch[39] Loss: 0.0067\n",
            "Epoch[39] Loss: 0.0075\n",
            "Epoch[39] Loss: 0.0071\n",
            "Epoch[39] Loss: 0.0077\n",
            "Epoch[39] Loss: 0.0075\n",
            "Epoch[39] Loss: 0.0082\n",
            "Epoch[39] Loss: 0.0085\n",
            "Epoch[39] Loss: 0.0063\n",
            "Epoch[39] Loss: 0.0132\n",
            "Training Results - Epoch: 39  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 39  Avg loss: 0.0082\n",
            "Epoch[40] Loss: 0.0047\n",
            "Epoch[40] Loss: 0.0043\n",
            "Epoch[40] Loss: 0.0064\n",
            "Epoch[40] Loss: 0.0073\n",
            "Epoch[40] Loss: 0.0067\n",
            "Epoch[40] Loss: 0.0067\n",
            "Epoch[40] Loss: 0.0088\n",
            "Epoch[40] Loss: 0.0089\n",
            "Epoch[40] Loss: 0.0058\n",
            "Epoch[40] Loss: 0.0097\n",
            "Epoch[40] Loss: 0.0055\n",
            "Epoch[40] Loss: 0.0080\n",
            "Epoch[40] Loss: 0.0068\n",
            "Epoch[40] Loss: 0.0064\n",
            "Epoch[40] Loss: 0.0060\n",
            "Epoch[40] Loss: 0.0078\n",
            "Epoch[40] Loss: 0.0089\n",
            "Epoch[40] Loss: 0.0066\n",
            "Epoch[40] Loss: 0.0062\n",
            "Training Results - Epoch: 40  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 40  Avg loss: 0.0079\n",
            "Epoch[41] Loss: 0.0058\n",
            "Epoch[41] Loss: 0.0101\n",
            "Epoch[41] Loss: 0.0069\n",
            "Epoch[41] Loss: 0.0066\n",
            "Epoch[41] Loss: 0.0069\n",
            "Epoch[41] Loss: 0.0079\n",
            "Epoch[41] Loss: 0.0064\n",
            "Epoch[41] Loss: 0.0052\n",
            "Epoch[41] Loss: 0.0072\n",
            "Epoch[41] Loss: 0.0050\n",
            "Epoch[41] Loss: 0.0070\n",
            "Epoch[41] Loss: 0.0069\n",
            "Epoch[41] Loss: 0.0076\n",
            "Epoch[41] Loss: 0.0059\n",
            "Epoch[41] Loss: 0.0073\n",
            "Epoch[41] Loss: 0.0056\n",
            "Epoch[41] Loss: 0.0049\n",
            "Epoch[41] Loss: 0.0081\n",
            "Epoch[41] Loss: 0.0155\n",
            "Training Results - Epoch: 41  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 41  Avg loss: 0.0074\n",
            "Epoch[42] Loss: 0.0071\n",
            "Epoch[42] Loss: 0.0056\n",
            "Epoch[42] Loss: 0.0059\n",
            "Epoch[42] Loss: 0.0059\n",
            "Epoch[42] Loss: 0.0063\n",
            "Epoch[42] Loss: 0.0069\n",
            "Epoch[42] Loss: 0.0077\n",
            "Epoch[42] Loss: 0.0052\n",
            "Epoch[42] Loss: 0.0069\n",
            "Epoch[42] Loss: 0.0096\n",
            "Epoch[42] Loss: 0.0063\n",
            "Epoch[42] Loss: 0.0078\n",
            "Epoch[42] Loss: 0.0076\n",
            "Epoch[42] Loss: 0.0066\n",
            "Epoch[42] Loss: 0.0059\n",
            "Epoch[42] Loss: 0.0088\n",
            "Epoch[42] Loss: 0.0070\n",
            "Epoch[42] Loss: 0.0074\n",
            "Epoch[42] Loss: 0.0098\n",
            "Training Results - Epoch: 42  Avg loss: 0.0069\n",
            "Validation Results - Epoch: 42  Avg loss: 0.0080\n",
            "Epoch[43] Loss: 0.0073\n",
            "Epoch[43] Loss: 0.0058\n",
            "Epoch[43] Loss: 0.0096\n",
            "Epoch[43] Loss: 0.0065\n",
            "Epoch[43] Loss: 0.0049\n",
            "Epoch[43] Loss: 0.0058\n",
            "Epoch[43] Loss: 0.0066\n",
            "Epoch[43] Loss: 0.0052\n",
            "Epoch[43] Loss: 0.0058\n",
            "Epoch[43] Loss: 0.0090\n",
            "Epoch[43] Loss: 0.0070\n",
            "Epoch[43] Loss: 0.0062\n",
            "Epoch[43] Loss: 0.0059\n",
            "Epoch[43] Loss: 0.0099\n",
            "Epoch[43] Loss: 0.0061\n",
            "Epoch[43] Loss: 0.0067\n",
            "Epoch[43] Loss: 0.0059\n",
            "Epoch[43] Loss: 0.0081\n",
            "Epoch[43] Loss: 0.0108\n",
            "Training Results - Epoch: 43  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 43  Avg loss: 0.0076\n",
            "Epoch[44] Loss: 0.0068\n",
            "Epoch[44] Loss: 0.0064\n",
            "Epoch[44] Loss: 0.0077\n",
            "Epoch[44] Loss: 0.0062\n",
            "Epoch[44] Loss: 0.0060\n",
            "Epoch[44] Loss: 0.0049\n",
            "Epoch[44] Loss: 0.0082\n",
            "Epoch[44] Loss: 0.0104\n",
            "Epoch[44] Loss: 0.0082\n",
            "Epoch[44] Loss: 0.0056\n",
            "Epoch[44] Loss: 0.0068\n",
            "Epoch[44] Loss: 0.0055\n",
            "Epoch[44] Loss: 0.0114\n",
            "Epoch[44] Loss: 0.0076\n",
            "Epoch[44] Loss: 0.0074\n",
            "Epoch[44] Loss: 0.0070\n",
            "Epoch[44] Loss: 0.0051\n",
            "Epoch[44] Loss: 0.0073\n",
            "Epoch[44] Loss: 0.0079\n",
            "Training Results - Epoch: 44  Avg loss: 0.0064\n",
            "Validation Results - Epoch: 44  Avg loss: 0.0080\n",
            "Epoch[45] Loss: 0.0057\n",
            "Epoch[45] Loss: 0.0059\n",
            "Epoch[45] Loss: 0.0051\n",
            "Epoch[45] Loss: 0.0065\n",
            "Epoch[45] Loss: 0.0066\n",
            "Epoch[45] Loss: 0.0076\n",
            "Epoch[45] Loss: 0.0080\n",
            "Epoch[45] Loss: 0.0069\n",
            "Epoch[45] Loss: 0.0053\n",
            "Epoch[45] Loss: 0.0061\n",
            "Epoch[45] Loss: 0.0064\n",
            "Epoch[45] Loss: 0.0079\n",
            "Epoch[45] Loss: 0.0052\n",
            "Epoch[45] Loss: 0.0077\n",
            "Epoch[45] Loss: 0.0063\n",
            "Epoch[45] Loss: 0.0073\n",
            "Epoch[45] Loss: 0.0054\n",
            "Epoch[45] Loss: 0.0069\n",
            "Epoch[45] Loss: 0.0156\n",
            "Training Results - Epoch: 45  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 45  Avg loss: 0.0075\n",
            "Epoch[46] Loss: 0.0070\n",
            "Epoch[46] Loss: 0.0094\n",
            "Epoch[46] Loss: 0.0047\n",
            "Epoch[46] Loss: 0.0079\n",
            "Epoch[46] Loss: 0.0068\n",
            "Epoch[46] Loss: 0.0050\n",
            "Epoch[46] Loss: 0.0064\n",
            "Epoch[46] Loss: 0.0061\n",
            "Epoch[46] Loss: 0.0070\n",
            "Epoch[46] Loss: 0.0063\n",
            "Epoch[46] Loss: 0.0082\n",
            "Epoch[46] Loss: 0.0078\n",
            "Epoch[46] Loss: 0.0068\n",
            "Epoch[46] Loss: 0.0080\n",
            "Epoch[46] Loss: 0.0049\n",
            "Epoch[46] Loss: 0.0077\n",
            "Epoch[46] Loss: 0.0065\n",
            "Epoch[46] Loss: 0.0101\n",
            "Epoch[46] Loss: 0.0097\n",
            "Training Results - Epoch: 46  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 46  Avg loss: 0.0073\n",
            "Epoch[47] Loss: 0.0066\n",
            "Epoch[47] Loss: 0.0066\n",
            "Epoch[47] Loss: 0.0076\n",
            "Epoch[47] Loss: 0.0054\n",
            "Epoch[47] Loss: 0.0063\n",
            "Epoch[47] Loss: 0.0050\n",
            "Epoch[47] Loss: 0.0093\n",
            "Epoch[47] Loss: 0.0078\n",
            "Epoch[47] Loss: 0.0060\n",
            "Epoch[47] Loss: 0.0065\n",
            "Epoch[47] Loss: 0.0073\n",
            "Epoch[47] Loss: 0.0072\n",
            "Epoch[47] Loss: 0.0063\n",
            "Epoch[47] Loss: 0.0083\n",
            "Epoch[47] Loss: 0.0058\n",
            "Epoch[47] Loss: 0.0078\n",
            "Epoch[47] Loss: 0.0051\n",
            "Epoch[47] Loss: 0.0063\n",
            "Epoch[47] Loss: 0.0042\n",
            "Training Results - Epoch: 47  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 47  Avg loss: 0.0075\n",
            "Epoch[48] Loss: 0.0070\n",
            "Epoch[48] Loss: 0.0083\n",
            "Epoch[48] Loss: 0.0090\n",
            "Epoch[48] Loss: 0.0052\n",
            "Epoch[48] Loss: 0.0067\n",
            "Epoch[48] Loss: 0.0078\n",
            "Epoch[48] Loss: 0.0078\n",
            "Epoch[48] Loss: 0.0057\n",
            "Epoch[48] Loss: 0.0049\n",
            "Epoch[48] Loss: 0.0067\n",
            "Epoch[48] Loss: 0.0072\n",
            "Epoch[48] Loss: 0.0061\n",
            "Epoch[48] Loss: 0.0094\n",
            "Epoch[48] Loss: 0.0055\n",
            "Epoch[48] Loss: 0.0058\n",
            "Epoch[48] Loss: 0.0051\n",
            "Epoch[48] Loss: 0.0063\n",
            "Epoch[48] Loss: 0.0057\n",
            "Epoch[48] Loss: 0.0094\n",
            "Training Results - Epoch: 48  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 48  Avg loss: 0.0076\n",
            "Epoch[49] Loss: 0.0076\n",
            "Epoch[49] Loss: 0.0072\n",
            "Epoch[49] Loss: 0.0060\n",
            "Epoch[49] Loss: 0.0085\n",
            "Epoch[49] Loss: 0.0076\n",
            "Epoch[49] Loss: 0.0045\n",
            "Epoch[49] Loss: 0.0063\n",
            "Epoch[49] Loss: 0.0080\n",
            "Epoch[49] Loss: 0.0050\n",
            "Epoch[49] Loss: 0.0049\n",
            "Epoch[49] Loss: 0.0067\n",
            "Epoch[49] Loss: 0.0067\n",
            "Epoch[49] Loss: 0.0065\n",
            "Epoch[49] Loss: 0.0076\n",
            "Epoch[49] Loss: 0.0076\n",
            "Epoch[49] Loss: 0.0082\n",
            "Epoch[49] Loss: 0.0059\n",
            "Epoch[49] Loss: 0.0061\n",
            "Epoch[49] Loss: 0.0063\n",
            "Training Results - Epoch: 49  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 49  Avg loss: 0.0074\n",
            "Epoch[50] Loss: 0.0067\n",
            "Epoch[50] Loss: 0.0081\n",
            "Epoch[50] Loss: 0.0074\n",
            "Epoch[50] Loss: 0.0077\n",
            "Epoch[50] Loss: 0.0058\n",
            "Epoch[50] Loss: 0.0056\n",
            "Epoch[50] Loss: 0.0084\n",
            "Epoch[50] Loss: 0.0071\n",
            "Epoch[50] Loss: 0.0058\n",
            "Epoch[50] Loss: 0.0062\n",
            "Epoch[50] Loss: 0.0065\n",
            "Epoch[50] Loss: 0.0066\n",
            "Epoch[50] Loss: 0.0062\n",
            "Epoch[50] Loss: 0.0059\n",
            "Epoch[50] Loss: 0.0053\n",
            "Epoch[50] Loss: 0.0115\n",
            "Epoch[50] Loss: 0.0086\n",
            "Epoch[50] Loss: 0.0046\n",
            "Epoch[50] Loss: 0.0045\n",
            "Training Results - Epoch: 50  Avg loss: 0.0058\n",
            "Validation Results - Epoch: 50  Avg loss: 0.0072\n",
            "Epoch[51] Loss: 0.0077\n",
            "Epoch[51] Loss: 0.0043\n",
            "Epoch[51] Loss: 0.0068\n",
            "Epoch[51] Loss: 0.0075\n",
            "Epoch[51] Loss: 0.0073\n",
            "Epoch[51] Loss: 0.0064\n",
            "Epoch[51] Loss: 0.0053\n",
            "Epoch[51] Loss: 0.0062\n",
            "Epoch[51] Loss: 0.0057\n",
            "Epoch[51] Loss: 0.0067\n",
            "Epoch[51] Loss: 0.0092\n",
            "Epoch[51] Loss: 0.0048\n",
            "Epoch[51] Loss: 0.0090\n",
            "Epoch[51] Loss: 0.0061\n",
            "Epoch[51] Loss: 0.0063\n",
            "Epoch[51] Loss: 0.0069\n",
            "Epoch[51] Loss: 0.0071\n",
            "Epoch[51] Loss: 0.0057\n",
            "Epoch[51] Loss: 0.0083\n",
            "Training Results - Epoch: 51  Avg loss: 0.0056\n",
            "Validation Results - Epoch: 51  Avg loss: 0.0074\n",
            "Epoch[52] Loss: 0.0068\n",
            "Epoch[52] Loss: 0.0079\n",
            "Epoch[52] Loss: 0.0070\n",
            "Epoch[52] Loss: 0.0059\n",
            "Epoch[52] Loss: 0.0060\n",
            "Epoch[52] Loss: 0.0080\n",
            "Epoch[52] Loss: 0.0058\n",
            "Epoch[52] Loss: 0.0064\n",
            "Epoch[52] Loss: 0.0060\n",
            "Epoch[52] Loss: 0.0080\n",
            "Epoch[52] Loss: 0.0062\n",
            "Epoch[52] Loss: 0.0062\n",
            "Epoch[52] Loss: 0.0067\n",
            "Epoch[52] Loss: 0.0061\n",
            "Epoch[52] Loss: 0.0104\n",
            "Epoch[52] Loss: 0.0084\n",
            "Epoch[52] Loss: 0.0061\n",
            "Epoch[52] Loss: 0.0071\n",
            "Epoch[52] Loss: 0.0073\n",
            "Training Results - Epoch: 52  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 52  Avg loss: 0.0073\n",
            "Epoch[53] Loss: 0.0075\n",
            "Epoch[53] Loss: 0.0044\n",
            "Epoch[53] Loss: 0.0070\n",
            "Epoch[53] Loss: 0.0065\n",
            "Epoch[53] Loss: 0.0079\n",
            "Epoch[53] Loss: 0.0058\n",
            "Epoch[53] Loss: 0.0051\n",
            "Epoch[53] Loss: 0.0051\n",
            "Epoch[53] Loss: 0.0073\n",
            "Epoch[53] Loss: 0.0085\n",
            "Epoch[53] Loss: 0.0061\n",
            "Epoch[53] Loss: 0.0063\n",
            "Epoch[53] Loss: 0.0080\n",
            "Epoch[53] Loss: 0.0083\n",
            "Epoch[53] Loss: 0.0059\n",
            "Epoch[53] Loss: 0.0065\n",
            "Epoch[53] Loss: 0.0058\n",
            "Epoch[53] Loss: 0.0055\n",
            "Epoch[53] Loss: 0.0049\n",
            "Training Results - Epoch: 53  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 53  Avg loss: 0.0078\n",
            "Epoch[54] Loss: 0.0124\n",
            "Epoch[54] Loss: 0.0056\n",
            "Epoch[54] Loss: 0.0051\n",
            "Epoch[54] Loss: 0.0047\n",
            "Epoch[54] Loss: 0.0062\n",
            "Epoch[54] Loss: 0.0065\n",
            "Epoch[54] Loss: 0.0063\n",
            "Epoch[54] Loss: 0.0082\n",
            "Epoch[54] Loss: 0.0069\n",
            "Epoch[54] Loss: 0.0054\n",
            "Epoch[54] Loss: 0.0089\n",
            "Epoch[54] Loss: 0.0076\n",
            "Epoch[54] Loss: 0.0057\n",
            "Epoch[54] Loss: 0.0063\n",
            "Epoch[54] Loss: 0.0082\n",
            "Epoch[54] Loss: 0.0081\n",
            "Epoch[54] Loss: 0.0067\n",
            "Epoch[54] Loss: 0.0072\n",
            "Epoch[54] Loss: 0.0136\n",
            "Training Results - Epoch: 54  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 54  Avg loss: 0.0080\n",
            "Epoch[55] Loss: 0.0078\n",
            "Epoch[55] Loss: 0.0062\n",
            "Epoch[55] Loss: 0.0060\n",
            "Epoch[55] Loss: 0.0074\n",
            "Epoch[55] Loss: 0.0063\n",
            "Epoch[55] Loss: 0.0077\n",
            "Epoch[55] Loss: 0.0078\n",
            "Epoch[55] Loss: 0.0079\n",
            "Epoch[55] Loss: 0.0095\n",
            "Epoch[55] Loss: 0.0049\n",
            "Epoch[55] Loss: 0.0048\n",
            "Epoch[55] Loss: 0.0059\n",
            "Epoch[55] Loss: 0.0073\n",
            "Epoch[55] Loss: 0.0050\n",
            "Epoch[55] Loss: 0.0057\n",
            "Epoch[55] Loss: 0.0072\n",
            "Epoch[55] Loss: 0.0096\n",
            "Epoch[55] Loss: 0.0070\n",
            "Epoch[55] Loss: 0.0060\n",
            "Training Results - Epoch: 55  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 55  Avg loss: 0.0082\n",
            "Epoch[56] Loss: 0.0073\n",
            "Epoch[56] Loss: 0.0074\n",
            "Epoch[56] Loss: 0.0069\n",
            "Epoch[56] Loss: 0.0071\n",
            "Epoch[56] Loss: 0.0047\n",
            "Epoch[56] Loss: 0.0052\n",
            "Epoch[56] Loss: 0.0079\n",
            "Epoch[56] Loss: 0.0062\n",
            "Epoch[56] Loss: 0.0076\n",
            "Epoch[56] Loss: 0.0060\n",
            "Epoch[56] Loss: 0.0063\n",
            "Epoch[56] Loss: 0.0062\n",
            "Epoch[56] Loss: 0.0073\n",
            "Epoch[56] Loss: 0.0074\n",
            "Epoch[56] Loss: 0.0066\n",
            "Epoch[56] Loss: 0.0064\n",
            "Epoch[56] Loss: 0.0067\n",
            "Epoch[56] Loss: 0.0050\n",
            "Epoch[56] Loss: 0.0069\n",
            "Training Results - Epoch: 56  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 56  Avg loss: 0.0079\n",
            "Epoch[57] Loss: 0.0081\n",
            "Epoch[57] Loss: 0.0058\n",
            "Epoch[57] Loss: 0.0072\n",
            "Epoch[57] Loss: 0.0100\n",
            "Epoch[57] Loss: 0.0051\n",
            "Epoch[57] Loss: 0.0057\n",
            "Epoch[57] Loss: 0.0073\n",
            "Epoch[57] Loss: 0.0063\n",
            "Epoch[57] Loss: 0.0054\n",
            "Epoch[57] Loss: 0.0064\n",
            "Epoch[57] Loss: 0.0056\n",
            "Epoch[57] Loss: 0.0054\n",
            "Epoch[57] Loss: 0.0046\n",
            "Epoch[57] Loss: 0.0088\n",
            "Epoch[57] Loss: 0.0073\n",
            "Epoch[57] Loss: 0.0071\n",
            "Epoch[57] Loss: 0.0062\n",
            "Epoch[57] Loss: 0.0085\n",
            "Epoch[57] Loss: 0.0102\n",
            "Training Results - Epoch: 57  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 57  Avg loss: 0.0076\n",
            "Epoch[58] Loss: 0.0058\n",
            "Epoch[58] Loss: 0.0052\n",
            "Epoch[58] Loss: 0.0076\n",
            "Epoch[58] Loss: 0.0054\n",
            "Epoch[58] Loss: 0.0055\n",
            "Epoch[58] Loss: 0.0057\n",
            "Epoch[58] Loss: 0.0065\n",
            "Epoch[58] Loss: 0.0076\n",
            "Epoch[58] Loss: 0.0078\n",
            "Epoch[58] Loss: 0.0069\n",
            "Epoch[58] Loss: 0.0081\n",
            "Epoch[58] Loss: 0.0105\n",
            "Epoch[58] Loss: 0.0098\n",
            "Epoch[58] Loss: 0.0056\n",
            "Epoch[58] Loss: 0.0063\n",
            "Epoch[58] Loss: 0.0065\n",
            "Epoch[58] Loss: 0.0074\n",
            "Epoch[58] Loss: 0.0060\n",
            "Epoch[58] Loss: 0.0085\n",
            "Training Results - Epoch: 58  Avg loss: 0.0058\n",
            "Validation Results - Epoch: 58  Avg loss: 0.0076\n",
            "Epoch[59] Loss: 0.0059\n",
            "Epoch[59] Loss: 0.0059\n",
            "Epoch[59] Loss: 0.0045\n",
            "Epoch[59] Loss: 0.0103\n",
            "Epoch[59] Loss: 0.0075\n",
            "Epoch[59] Loss: 0.0052\n",
            "Epoch[59] Loss: 0.0054\n",
            "Epoch[59] Loss: 0.0076\n",
            "Epoch[59] Loss: 0.0078\n",
            "Epoch[59] Loss: 0.0070\n",
            "Epoch[59] Loss: 0.0063\n",
            "Epoch[59] Loss: 0.0080\n",
            "Epoch[59] Loss: 0.0059\n",
            "Epoch[59] Loss: 0.0091\n",
            "Epoch[59] Loss: 0.0072\n",
            "Epoch[59] Loss: 0.0067\n",
            "Epoch[59] Loss: 0.0063\n",
            "Epoch[59] Loss: 0.0073\n",
            "Epoch[59] Loss: 0.0068\n",
            "Training Results - Epoch: 59  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 59  Avg loss: 0.0077\n",
            "Epoch[60] Loss: 0.0064\n",
            "Epoch[60] Loss: 0.0072\n",
            "Epoch[60] Loss: 0.0066\n",
            "Epoch[60] Loss: 0.0054\n",
            "Epoch[60] Loss: 0.0079\n",
            "Epoch[60] Loss: 0.0064\n",
            "Epoch[60] Loss: 0.0087\n",
            "Epoch[60] Loss: 0.0064\n",
            "Epoch[60] Loss: 0.0066\n",
            "Epoch[60] Loss: 0.0051\n",
            "Epoch[60] Loss: 0.0069\n",
            "Epoch[60] Loss: 0.0057\n",
            "Epoch[60] Loss: 0.0079\n",
            "Epoch[60] Loss: 0.0082\n",
            "Epoch[60] Loss: 0.0052\n",
            "Epoch[60] Loss: 0.0086\n",
            "Epoch[60] Loss: 0.0094\n",
            "Epoch[60] Loss: 0.0076\n",
            "Epoch[60] Loss: 0.0074\n",
            "Training Results - Epoch: 60  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 60  Avg loss: 0.0079\n",
            "Epoch[61] Loss: 0.0072\n",
            "Epoch[61] Loss: 0.0074\n",
            "Epoch[61] Loss: 0.0093\n",
            "Epoch[61] Loss: 0.0061\n",
            "Epoch[61] Loss: 0.0060\n",
            "Epoch[61] Loss: 0.0069\n",
            "Epoch[61] Loss: 0.0074\n",
            "Epoch[61] Loss: 0.0061\n",
            "Epoch[61] Loss: 0.0055\n",
            "Epoch[61] Loss: 0.0082\n",
            "Epoch[61] Loss: 0.0081\n",
            "Epoch[61] Loss: 0.0075\n",
            "Epoch[61] Loss: 0.0089\n",
            "Epoch[61] Loss: 0.0057\n",
            "Epoch[61] Loss: 0.0055\n",
            "Epoch[61] Loss: 0.0105\n",
            "Epoch[61] Loss: 0.0070\n",
            "Epoch[61] Loss: 0.0084\n",
            "Epoch[61] Loss: 0.0076\n",
            "Training Results - Epoch: 61  Avg loss: 0.0056\n",
            "Validation Results - Epoch: 61  Avg loss: 0.0078\n",
            "Epoch[62] Loss: 0.0061\n",
            "Epoch[62] Loss: 0.0073\n",
            "Epoch[62] Loss: 0.0083\n",
            "Epoch[62] Loss: 0.0059\n",
            "Epoch[62] Loss: 0.0065\n",
            "Epoch[62] Loss: 0.0082\n",
            "Epoch[62] Loss: 0.0068\n",
            "Epoch[62] Loss: 0.0073\n",
            "Epoch[62] Loss: 0.0059\n",
            "Epoch[62] Loss: 0.0095\n",
            "Epoch[62] Loss: 0.0045\n",
            "Epoch[62] Loss: 0.0061\n",
            "Epoch[62] Loss: 0.0055\n",
            "Epoch[62] Loss: 0.0071\n",
            "Epoch[62] Loss: 0.0065\n",
            "Epoch[62] Loss: 0.0050\n",
            "Epoch[62] Loss: 0.0066\n",
            "Epoch[62] Loss: 0.0072\n",
            "Epoch[62] Loss: 0.0079\n",
            "Training Results - Epoch: 62  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 62  Avg loss: 0.0080\n",
            "Epoch[63] Loss: 0.0051\n",
            "Epoch[63] Loss: 0.0074\n",
            "Epoch[63] Loss: 0.0064\n",
            "Epoch[63] Loss: 0.0062\n",
            "Epoch[63] Loss: 0.0060\n",
            "Epoch[63] Loss: 0.0045\n",
            "Epoch[63] Loss: 0.0055\n",
            "Epoch[63] Loss: 0.0070\n",
            "Epoch[63] Loss: 0.0082\n",
            "Epoch[63] Loss: 0.0074\n",
            "Epoch[63] Loss: 0.0084\n",
            "Epoch[63] Loss: 0.0072\n",
            "Epoch[63] Loss: 0.0053\n",
            "Epoch[63] Loss: 0.0063\n",
            "Epoch[63] Loss: 0.0063\n",
            "Epoch[63] Loss: 0.0063\n",
            "Epoch[63] Loss: 0.0075\n",
            "Epoch[63] Loss: 0.0061\n",
            "Epoch[63] Loss: 0.0065\n",
            "Training Results - Epoch: 63  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 63  Avg loss: 0.0087\n",
            "Epoch[64] Loss: 0.0074\n",
            "Epoch[64] Loss: 0.0073\n",
            "Epoch[64] Loss: 0.0066\n",
            "Epoch[64] Loss: 0.0064\n",
            "Epoch[64] Loss: 0.0093\n",
            "Epoch[64] Loss: 0.0060\n",
            "Epoch[64] Loss: 0.0051\n",
            "Epoch[64] Loss: 0.0060\n",
            "Epoch[64] Loss: 0.0056\n",
            "Epoch[64] Loss: 0.0067\n",
            "Epoch[64] Loss: 0.0056\n",
            "Epoch[64] Loss: 0.0074\n",
            "Epoch[64] Loss: 0.0056\n",
            "Epoch[64] Loss: 0.0082\n",
            "Epoch[64] Loss: 0.0058\n",
            "Epoch[64] Loss: 0.0062\n",
            "Epoch[64] Loss: 0.0069\n",
            "Epoch[64] Loss: 0.0084\n",
            "Epoch[64] Loss: 0.0042\n",
            "Training Results - Epoch: 64  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 64  Avg loss: 0.0078\n",
            "Epoch[65] Loss: 0.0068\n",
            "Epoch[65] Loss: 0.0099\n",
            "Epoch[65] Loss: 0.0072\n",
            "Epoch[65] Loss: 0.0077\n",
            "Epoch[65] Loss: 0.0071\n",
            "Epoch[65] Loss: 0.0066\n",
            "Epoch[65] Loss: 0.0086\n",
            "Epoch[65] Loss: 0.0072\n",
            "Epoch[65] Loss: 0.0071\n",
            "Epoch[65] Loss: 0.0071\n",
            "Epoch[65] Loss: 0.0061\n",
            "Epoch[65] Loss: 0.0088\n",
            "Epoch[65] Loss: 0.0061\n",
            "Epoch[65] Loss: 0.0057\n",
            "Epoch[65] Loss: 0.0082\n",
            "Epoch[65] Loss: 0.0054\n",
            "Epoch[65] Loss: 0.0066\n",
            "Epoch[65] Loss: 0.0056\n",
            "Epoch[65] Loss: 0.0073\n",
            "Training Results - Epoch: 65  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 65  Avg loss: 0.0075\n",
            "Epoch[66] Loss: 0.0064\n",
            "Epoch[66] Loss: 0.0055\n",
            "Epoch[66] Loss: 0.0095\n",
            "Epoch[66] Loss: 0.0084\n",
            "Epoch[66] Loss: 0.0089\n",
            "Epoch[66] Loss: 0.0079\n",
            "Epoch[66] Loss: 0.0055\n",
            "Epoch[66] Loss: 0.0062\n",
            "Epoch[66] Loss: 0.0070\n",
            "Epoch[66] Loss: 0.0061\n",
            "Epoch[66] Loss: 0.0071\n",
            "Epoch[66] Loss: 0.0052\n",
            "Epoch[66] Loss: 0.0066\n",
            "Epoch[66] Loss: 0.0075\n",
            "Epoch[66] Loss: 0.0062\n",
            "Epoch[66] Loss: 0.0065\n",
            "Epoch[66] Loss: 0.0054\n",
            "Epoch[66] Loss: 0.0056\n",
            "Epoch[66] Loss: 0.0064\n",
            "Training Results - Epoch: 66  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 66  Avg loss: 0.0076\n",
            "Epoch[67] Loss: 0.0080\n",
            "Epoch[67] Loss: 0.0066\n",
            "Epoch[67] Loss: 0.0061\n",
            "Epoch[67] Loss: 0.0058\n",
            "Epoch[67] Loss: 0.0054\n",
            "Epoch[67] Loss: 0.0052\n",
            "Epoch[67] Loss: 0.0067\n",
            "Epoch[67] Loss: 0.0072\n",
            "Epoch[67] Loss: 0.0102\n",
            "Epoch[67] Loss: 0.0058\n",
            "Epoch[67] Loss: 0.0088\n",
            "Epoch[67] Loss: 0.0083\n",
            "Epoch[67] Loss: 0.0077\n",
            "Epoch[67] Loss: 0.0066\n",
            "Epoch[67] Loss: 0.0083\n",
            "Epoch[67] Loss: 0.0048\n",
            "Epoch[67] Loss: 0.0066\n",
            "Epoch[67] Loss: 0.0094\n",
            "Epoch[67] Loss: 0.0111\n",
            "Training Results - Epoch: 67  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 67  Avg loss: 0.0089\n",
            "Epoch[68] Loss: 0.0062\n",
            "Epoch[68] Loss: 0.0061\n",
            "Epoch[68] Loss: 0.0069\n",
            "Epoch[68] Loss: 0.0078\n",
            "Epoch[68] Loss: 0.0068\n",
            "Epoch[68] Loss: 0.0068\n",
            "Epoch[68] Loss: 0.0077\n",
            "Epoch[68] Loss: 0.0074\n",
            "Epoch[68] Loss: 0.0064\n",
            "Epoch[68] Loss: 0.0074\n",
            "Epoch[68] Loss: 0.0048\n",
            "Epoch[68] Loss: 0.0062\n",
            "Epoch[68] Loss: 0.0065\n",
            "Epoch[68] Loss: 0.0070\n",
            "Epoch[68] Loss: 0.0078\n",
            "Epoch[68] Loss: 0.0078\n",
            "Epoch[68] Loss: 0.0074\n",
            "Epoch[68] Loss: 0.0061\n",
            "Epoch[68] Loss: 0.0055\n",
            "Training Results - Epoch: 68  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 68  Avg loss: 0.0076\n",
            "Epoch[69] Loss: 0.0053\n",
            "Epoch[69] Loss: 0.0063\n",
            "Epoch[69] Loss: 0.0070\n",
            "Epoch[69] Loss: 0.0065\n",
            "Epoch[69] Loss: 0.0065\n",
            "Epoch[69] Loss: 0.0071\n",
            "Epoch[69] Loss: 0.0055\n",
            "Epoch[69] Loss: 0.0078\n",
            "Epoch[69] Loss: 0.0069\n",
            "Epoch[69] Loss: 0.0060\n",
            "Epoch[69] Loss: 0.0052\n",
            "Epoch[69] Loss: 0.0073\n",
            "Epoch[69] Loss: 0.0047\n",
            "Epoch[69] Loss: 0.0057\n",
            "Epoch[69] Loss: 0.0066\n",
            "Epoch[69] Loss: 0.0084\n",
            "Epoch[69] Loss: 0.0064\n",
            "Epoch[69] Loss: 0.0075\n",
            "Epoch[69] Loss: 0.0058\n",
            "Training Results - Epoch: 69  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 69  Avg loss: 0.0070\n",
            "Epoch[70] Loss: 0.0084\n",
            "Epoch[70] Loss: 0.0058\n",
            "Epoch[70] Loss: 0.0083\n",
            "Epoch[70] Loss: 0.0058\n",
            "Epoch[70] Loss: 0.0073\n",
            "Epoch[70] Loss: 0.0052\n",
            "Epoch[70] Loss: 0.0070\n",
            "Epoch[70] Loss: 0.0067\n",
            "Epoch[70] Loss: 0.0066\n",
            "Epoch[70] Loss: 0.0068\n",
            "Epoch[70] Loss: 0.0068\n",
            "Epoch[70] Loss: 0.0059\n",
            "Epoch[70] Loss: 0.0062\n",
            "Epoch[70] Loss: 0.0067\n",
            "Epoch[70] Loss: 0.0066\n",
            "Epoch[70] Loss: 0.0079\n",
            "Epoch[70] Loss: 0.0067\n",
            "Epoch[70] Loss: 0.0060\n",
            "Epoch[70] Loss: 0.0074\n",
            "Training Results - Epoch: 70  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 70  Avg loss: 0.0084\n",
            "Epoch[71] Loss: 0.0068\n",
            "Epoch[71] Loss: 0.0061\n",
            "Epoch[71] Loss: 0.0074\n",
            "Epoch[71] Loss: 0.0056\n",
            "Epoch[71] Loss: 0.0075\n",
            "Epoch[71] Loss: 0.0067\n",
            "Epoch[71] Loss: 0.0050\n",
            "Epoch[71] Loss: 0.0056\n",
            "Epoch[71] Loss: 0.0064\n",
            "Epoch[71] Loss: 0.0058\n",
            "Epoch[71] Loss: 0.0058\n",
            "Epoch[71] Loss: 0.0073\n",
            "Epoch[71] Loss: 0.0081\n",
            "Epoch[71] Loss: 0.0077\n",
            "Epoch[71] Loss: 0.0104\n",
            "Epoch[71] Loss: 0.0051\n",
            "Epoch[71] Loss: 0.0078\n",
            "Epoch[71] Loss: 0.0085\n",
            "Epoch[71] Loss: 0.0119\n",
            "Training Results - Epoch: 71  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 71  Avg loss: 0.0084\n",
            "Epoch[72] Loss: 0.0068\n",
            "Epoch[72] Loss: 0.0052\n",
            "Epoch[72] Loss: 0.0075\n",
            "Epoch[72] Loss: 0.0055\n",
            "Epoch[72] Loss: 0.0055\n",
            "Epoch[72] Loss: 0.0089\n",
            "Epoch[72] Loss: 0.0048\n",
            "Epoch[72] Loss: 0.0065\n",
            "Epoch[72] Loss: 0.0055\n",
            "Epoch[72] Loss: 0.0073\n",
            "Epoch[72] Loss: 0.0059\n",
            "Epoch[72] Loss: 0.0063\n",
            "Epoch[72] Loss: 0.0052\n",
            "Epoch[72] Loss: 0.0062\n",
            "Epoch[72] Loss: 0.0072\n",
            "Epoch[72] Loss: 0.0053\n",
            "Epoch[72] Loss: 0.0075\n",
            "Epoch[72] Loss: 0.0099\n",
            "Epoch[72] Loss: 0.0055\n",
            "Training Results - Epoch: 72  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 72  Avg loss: 0.0079\n",
            "Epoch[73] Loss: 0.0083\n",
            "Epoch[73] Loss: 0.0065\n",
            "Epoch[73] Loss: 0.0072\n",
            "Epoch[73] Loss: 0.0067\n",
            "Epoch[73] Loss: 0.0068\n",
            "Epoch[73] Loss: 0.0082\n",
            "Epoch[73] Loss: 0.0076\n",
            "Epoch[73] Loss: 0.0065\n",
            "Epoch[73] Loss: 0.0070\n",
            "Epoch[73] Loss: 0.0065\n",
            "Epoch[73] Loss: 0.0073\n",
            "Epoch[73] Loss: 0.0059\n",
            "Epoch[73] Loss: 0.0057\n",
            "Epoch[73] Loss: 0.0077\n",
            "Epoch[73] Loss: 0.0063\n",
            "Epoch[73] Loss: 0.0076\n",
            "Epoch[73] Loss: 0.0061\n",
            "Epoch[73] Loss: 0.0067\n",
            "Epoch[73] Loss: 0.0089\n",
            "Training Results - Epoch: 73  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 73  Avg loss: 0.0078\n",
            "Epoch[74] Loss: 0.0072\n",
            "Epoch[74] Loss: 0.0066\n",
            "Epoch[74] Loss: 0.0070\n",
            "Epoch[74] Loss: 0.0057\n",
            "Epoch[74] Loss: 0.0065\n",
            "Epoch[74] Loss: 0.0067\n",
            "Epoch[74] Loss: 0.0079\n",
            "Epoch[74] Loss: 0.0068\n",
            "Epoch[74] Loss: 0.0078\n",
            "Epoch[74] Loss: 0.0079\n",
            "Epoch[74] Loss: 0.0071\n",
            "Epoch[74] Loss: 0.0055\n",
            "Epoch[74] Loss: 0.0071\n",
            "Epoch[74] Loss: 0.0085\n",
            "Epoch[74] Loss: 0.0065\n",
            "Epoch[74] Loss: 0.0050\n",
            "Epoch[74] Loss: 0.0086\n",
            "Epoch[74] Loss: 0.0061\n",
            "Epoch[74] Loss: 0.0060\n",
            "Training Results - Epoch: 74  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 74  Avg loss: 0.0071\n",
            "Epoch[75] Loss: 0.0075\n",
            "Epoch[75] Loss: 0.0071\n",
            "Epoch[75] Loss: 0.0089\n",
            "Epoch[75] Loss: 0.0063\n",
            "Epoch[75] Loss: 0.0072\n",
            "Epoch[75] Loss: 0.0047\n",
            "Epoch[75] Loss: 0.0066\n",
            "Epoch[75] Loss: 0.0075\n",
            "Epoch[75] Loss: 0.0062\n",
            "Epoch[75] Loss: 0.0075\n",
            "Epoch[75] Loss: 0.0092\n",
            "Epoch[75] Loss: 0.0089\n",
            "Epoch[75] Loss: 0.0059\n",
            "Epoch[75] Loss: 0.0059\n",
            "Epoch[75] Loss: 0.0078\n",
            "Epoch[75] Loss: 0.0072\n",
            "Epoch[75] Loss: 0.0083\n",
            "Epoch[75] Loss: 0.0072\n",
            "Epoch[75] Loss: 0.0054\n",
            "Training Results - Epoch: 75  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 75  Avg loss: 0.0079\n",
            "Epoch[76] Loss: 0.0082\n",
            "Epoch[76] Loss: 0.0091\n",
            "Epoch[76] Loss: 0.0054\n",
            "Epoch[76] Loss: 0.0070\n",
            "Epoch[76] Loss: 0.0075\n",
            "Epoch[76] Loss: 0.0055\n",
            "Epoch[76] Loss: 0.0060\n",
            "Epoch[76] Loss: 0.0043\n",
            "Epoch[76] Loss: 0.0087\n",
            "Epoch[76] Loss: 0.0060\n",
            "Epoch[76] Loss: 0.0076\n",
            "Epoch[76] Loss: 0.0053\n",
            "Epoch[76] Loss: 0.0074\n",
            "Epoch[76] Loss: 0.0073\n",
            "Epoch[76] Loss: 0.0059\n",
            "Epoch[76] Loss: 0.0081\n",
            "Epoch[76] Loss: 0.0068\n",
            "Epoch[76] Loss: 0.0072\n",
            "Epoch[76] Loss: 0.0075\n",
            "Training Results - Epoch: 76  Avg loss: 0.0063\n",
            "Validation Results - Epoch: 76  Avg loss: 0.0075\n",
            "Epoch[77] Loss: 0.0050\n",
            "Epoch[77] Loss: 0.0066\n",
            "Epoch[77] Loss: 0.0060\n",
            "Epoch[77] Loss: 0.0074\n",
            "Epoch[77] Loss: 0.0069\n",
            "Epoch[77] Loss: 0.0070\n",
            "Epoch[77] Loss: 0.0060\n",
            "Epoch[77] Loss: 0.0070\n",
            "Epoch[77] Loss: 0.0042\n",
            "Epoch[77] Loss: 0.0078\n",
            "Epoch[77] Loss: 0.0065\n",
            "Epoch[77] Loss: 0.0063\n",
            "Epoch[77] Loss: 0.0058\n",
            "Epoch[77] Loss: 0.0061\n",
            "Epoch[77] Loss: 0.0067\n",
            "Epoch[77] Loss: 0.0064\n",
            "Epoch[77] Loss: 0.0056\n",
            "Epoch[77] Loss: 0.0069\n",
            "Epoch[77] Loss: 0.0076\n",
            "Training Results - Epoch: 77  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 77  Avg loss: 0.0071\n",
            "Epoch[78] Loss: 0.0077\n",
            "Epoch[78] Loss: 0.0053\n",
            "Epoch[78] Loss: 0.0057\n",
            "Epoch[78] Loss: 0.0062\n",
            "Epoch[78] Loss: 0.0058\n",
            "Epoch[78] Loss: 0.0062\n",
            "Epoch[78] Loss: 0.0051\n",
            "Epoch[78] Loss: 0.0061\n",
            "Epoch[78] Loss: 0.0071\n",
            "Epoch[78] Loss: 0.0078\n",
            "Epoch[78] Loss: 0.0059\n",
            "Epoch[78] Loss: 0.0063\n",
            "Epoch[78] Loss: 0.0053\n",
            "Epoch[78] Loss: 0.0078\n",
            "Epoch[78] Loss: 0.0089\n",
            "Epoch[78] Loss: 0.0055\n",
            "Epoch[78] Loss: 0.0056\n",
            "Epoch[78] Loss: 0.0070\n",
            "Epoch[78] Loss: 0.0037\n",
            "Training Results - Epoch: 78  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 78  Avg loss: 0.0076\n",
            "Epoch[79] Loss: 0.0060\n",
            "Epoch[79] Loss: 0.0073\n",
            "Epoch[79] Loss: 0.0056\n",
            "Epoch[79] Loss: 0.0068\n",
            "Epoch[79] Loss: 0.0087\n",
            "Epoch[79] Loss: 0.0061\n",
            "Epoch[79] Loss: 0.0043\n",
            "Epoch[79] Loss: 0.0056\n",
            "Epoch[79] Loss: 0.0084\n",
            "Epoch[79] Loss: 0.0085\n",
            "Epoch[79] Loss: 0.0061\n",
            "Epoch[79] Loss: 0.0067\n",
            "Epoch[79] Loss: 0.0072\n",
            "Epoch[79] Loss: 0.0081\n",
            "Epoch[79] Loss: 0.0074\n",
            "Epoch[79] Loss: 0.0060\n",
            "Epoch[79] Loss: 0.0044\n",
            "Epoch[79] Loss: 0.0057\n",
            "Epoch[79] Loss: 0.0056\n",
            "Training Results - Epoch: 79  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 79  Avg loss: 0.0075\n",
            "Epoch[80] Loss: 0.0041\n",
            "Epoch[80] Loss: 0.0051\n",
            "Epoch[80] Loss: 0.0064\n",
            "Epoch[80] Loss: 0.0066\n",
            "Epoch[80] Loss: 0.0068\n",
            "Epoch[80] Loss: 0.0085\n",
            "Epoch[80] Loss: 0.0065\n",
            "Epoch[80] Loss: 0.0095\n",
            "Epoch[80] Loss: 0.0049\n",
            "Epoch[80] Loss: 0.0066\n",
            "Epoch[80] Loss: 0.0064\n",
            "Epoch[80] Loss: 0.0059\n",
            "Epoch[80] Loss: 0.0088\n",
            "Epoch[80] Loss: 0.0067\n",
            "Epoch[80] Loss: 0.0062\n",
            "Epoch[80] Loss: 0.0063\n",
            "Epoch[80] Loss: 0.0086\n",
            "Epoch[80] Loss: 0.0098\n",
            "Epoch[80] Loss: 0.0056\n",
            "Training Results - Epoch: 80  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 80  Avg loss: 0.0082\n",
            "Epoch[81] Loss: 0.0065\n",
            "Epoch[81] Loss: 0.0069\n",
            "Epoch[81] Loss: 0.0063\n",
            "Epoch[81] Loss: 0.0070\n",
            "Epoch[81] Loss: 0.0057\n",
            "Epoch[81] Loss: 0.0061\n",
            "Epoch[81] Loss: 0.0081\n",
            "Epoch[81] Loss: 0.0053\n",
            "Epoch[81] Loss: 0.0069\n",
            "Epoch[81] Loss: 0.0080\n",
            "Epoch[81] Loss: 0.0075\n",
            "Epoch[81] Loss: 0.0076\n",
            "Epoch[81] Loss: 0.0075\n",
            "Epoch[81] Loss: 0.0072\n",
            "Epoch[81] Loss: 0.0077\n",
            "Epoch[81] Loss: 0.0091\n",
            "Epoch[81] Loss: 0.0061\n",
            "Epoch[81] Loss: 0.0059\n",
            "Epoch[81] Loss: 0.0069\n",
            "Training Results - Epoch: 81  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 81  Avg loss: 0.0078\n",
            "Epoch[82] Loss: 0.0076\n",
            "Epoch[82] Loss: 0.0063\n",
            "Epoch[82] Loss: 0.0057\n",
            "Epoch[82] Loss: 0.0049\n",
            "Epoch[82] Loss: 0.0078\n",
            "Epoch[82] Loss: 0.0138\n",
            "Epoch[82] Loss: 0.0066\n",
            "Epoch[82] Loss: 0.0071\n",
            "Epoch[82] Loss: 0.0066\n",
            "Epoch[82] Loss: 0.0102\n",
            "Epoch[82] Loss: 0.0070\n",
            "Epoch[82] Loss: 0.0071\n",
            "Epoch[82] Loss: 0.0049\n",
            "Epoch[82] Loss: 0.0079\n",
            "Epoch[82] Loss: 0.0062\n",
            "Epoch[82] Loss: 0.0063\n",
            "Epoch[82] Loss: 0.0072\n",
            "Epoch[82] Loss: 0.0046\n",
            "Epoch[82] Loss: 0.0048\n",
            "Training Results - Epoch: 82  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 82  Avg loss: 0.0077\n",
            "Epoch[83] Loss: 0.0049\n",
            "Epoch[83] Loss: 0.0056\n",
            "Epoch[83] Loss: 0.0063\n",
            "Epoch[83] Loss: 0.0062\n",
            "Epoch[83] Loss: 0.0063\n",
            "Epoch[83] Loss: 0.0064\n",
            "Epoch[83] Loss: 0.0068\n",
            "Epoch[83] Loss: 0.0066\n",
            "Epoch[83] Loss: 0.0050\n",
            "Epoch[83] Loss: 0.0070\n",
            "Epoch[83] Loss: 0.0048\n",
            "Epoch[83] Loss: 0.0071\n",
            "Epoch[83] Loss: 0.0040\n",
            "Epoch[83] Loss: 0.0077\n",
            "Epoch[83] Loss: 0.0057\n",
            "Epoch[83] Loss: 0.0051\n",
            "Epoch[83] Loss: 0.0067\n",
            "Epoch[83] Loss: 0.0079\n",
            "Epoch[83] Loss: 0.0090\n",
            "Training Results - Epoch: 83  Avg loss: 0.0065\n",
            "Validation Results - Epoch: 83  Avg loss: 0.0079\n",
            "Epoch[84] Loss: 0.0063\n",
            "Epoch[84] Loss: 0.0058\n",
            "Epoch[84] Loss: 0.0061\n",
            "Epoch[84] Loss: 0.0067\n",
            "Epoch[84] Loss: 0.0054\n",
            "Epoch[84] Loss: 0.0068\n",
            "Epoch[84] Loss: 0.0064\n",
            "Epoch[84] Loss: 0.0079\n",
            "Epoch[84] Loss: 0.0070\n",
            "Epoch[84] Loss: 0.0054\n",
            "Epoch[84] Loss: 0.0079\n",
            "Epoch[84] Loss: 0.0067\n",
            "Epoch[84] Loss: 0.0060\n",
            "Epoch[84] Loss: 0.0063\n",
            "Epoch[84] Loss: 0.0063\n",
            "Epoch[84] Loss: 0.0087\n",
            "Epoch[84] Loss: 0.0076\n",
            "Epoch[84] Loss: 0.0073\n",
            "Epoch[84] Loss: 0.0057\n",
            "Training Results - Epoch: 84  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 84  Avg loss: 0.0077\n",
            "Epoch[85] Loss: 0.0065\n",
            "Epoch[85] Loss: 0.0066\n",
            "Epoch[85] Loss: 0.0080\n",
            "Epoch[85] Loss: 0.0061\n",
            "Epoch[85] Loss: 0.0062\n",
            "Epoch[85] Loss: 0.0061\n",
            "Epoch[85] Loss: 0.0056\n",
            "Epoch[85] Loss: 0.0050\n",
            "Epoch[85] Loss: 0.0074\n",
            "Epoch[85] Loss: 0.0071\n",
            "Epoch[85] Loss: 0.0073\n",
            "Epoch[85] Loss: 0.0065\n",
            "Epoch[85] Loss: 0.0067\n",
            "Epoch[85] Loss: 0.0060\n",
            "Epoch[85] Loss: 0.0059\n",
            "Epoch[85] Loss: 0.0085\n",
            "Epoch[85] Loss: 0.0072\n",
            "Epoch[85] Loss: 0.0061\n",
            "Epoch[85] Loss: 0.0099\n",
            "Training Results - Epoch: 85  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 85  Avg loss: 0.0081\n",
            "Epoch[86] Loss: 0.0083\n",
            "Epoch[86] Loss: 0.0059\n",
            "Epoch[86] Loss: 0.0075\n",
            "Epoch[86] Loss: 0.0058\n",
            "Epoch[86] Loss: 0.0074\n",
            "Epoch[86] Loss: 0.0066\n",
            "Epoch[86] Loss: 0.0061\n",
            "Epoch[86] Loss: 0.0101\n",
            "Epoch[86] Loss: 0.0065\n",
            "Epoch[86] Loss: 0.0071\n",
            "Epoch[86] Loss: 0.0071\n",
            "Epoch[86] Loss: 0.0054\n",
            "Epoch[86] Loss: 0.0058\n",
            "Epoch[86] Loss: 0.0067\n",
            "Epoch[86] Loss: 0.0068\n",
            "Epoch[86] Loss: 0.0056\n",
            "Epoch[86] Loss: 0.0074\n",
            "Epoch[86] Loss: 0.0072\n",
            "Epoch[86] Loss: 0.0059\n",
            "Training Results - Epoch: 86  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 86  Avg loss: 0.0078\n",
            "Epoch[87] Loss: 0.0071\n",
            "Epoch[87] Loss: 0.0061\n",
            "Epoch[87] Loss: 0.0062\n",
            "Epoch[87] Loss: 0.0059\n",
            "Epoch[87] Loss: 0.0073\n",
            "Epoch[87] Loss: 0.0051\n",
            "Epoch[87] Loss: 0.0064\n",
            "Epoch[87] Loss: 0.0084\n",
            "Epoch[87] Loss: 0.0063\n",
            "Epoch[87] Loss: 0.0070\n",
            "Epoch[87] Loss: 0.0097\n",
            "Epoch[87] Loss: 0.0064\n",
            "Epoch[87] Loss: 0.0044\n",
            "Epoch[87] Loss: 0.0075\n",
            "Epoch[87] Loss: 0.0084\n",
            "Epoch[87] Loss: 0.0080\n",
            "Epoch[87] Loss: 0.0076\n",
            "Epoch[87] Loss: 0.0048\n",
            "Epoch[87] Loss: 0.0071\n",
            "Training Results - Epoch: 87  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 87  Avg loss: 0.0077\n",
            "Epoch[88] Loss: 0.0054\n",
            "Epoch[88] Loss: 0.0075\n",
            "Epoch[88] Loss: 0.0083\n",
            "Epoch[88] Loss: 0.0086\n",
            "Epoch[88] Loss: 0.0056\n",
            "Epoch[88] Loss: 0.0067\n",
            "Epoch[88] Loss: 0.0084\n",
            "Epoch[88] Loss: 0.0054\n",
            "Epoch[88] Loss: 0.0062\n",
            "Epoch[88] Loss: 0.0062\n",
            "Epoch[88] Loss: 0.0084\n",
            "Epoch[88] Loss: 0.0064\n",
            "Epoch[88] Loss: 0.0052\n",
            "Epoch[88] Loss: 0.0060\n",
            "Epoch[88] Loss: 0.0101\n",
            "Epoch[88] Loss: 0.0046\n",
            "Epoch[88] Loss: 0.0054\n",
            "Epoch[88] Loss: 0.0045\n",
            "Epoch[88] Loss: 0.0065\n",
            "Training Results - Epoch: 88  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 88  Avg loss: 0.0077\n",
            "Epoch[89] Loss: 0.0052\n",
            "Epoch[89] Loss: 0.0066\n",
            "Epoch[89] Loss: 0.0064\n",
            "Epoch[89] Loss: 0.0056\n",
            "Epoch[89] Loss: 0.0069\n",
            "Epoch[89] Loss: 0.0077\n",
            "Epoch[89] Loss: 0.0056\n",
            "Epoch[89] Loss: 0.0064\n",
            "Epoch[89] Loss: 0.0118\n",
            "Epoch[89] Loss: 0.0070\n",
            "Epoch[89] Loss: 0.0073\n",
            "Epoch[89] Loss: 0.0069\n",
            "Epoch[89] Loss: 0.0103\n",
            "Epoch[89] Loss: 0.0059\n",
            "Epoch[89] Loss: 0.0074\n",
            "Epoch[89] Loss: 0.0059\n",
            "Epoch[89] Loss: 0.0074\n",
            "Epoch[89] Loss: 0.0075\n",
            "Epoch[89] Loss: 0.0079\n",
            "Training Results - Epoch: 89  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 89  Avg loss: 0.0077\n",
            "Epoch[90] Loss: 0.0073\n",
            "Epoch[90] Loss: 0.0069\n",
            "Epoch[90] Loss: 0.0072\n",
            "Epoch[90] Loss: 0.0058\n",
            "Epoch[90] Loss: 0.0057\n",
            "Epoch[90] Loss: 0.0092\n",
            "Epoch[90] Loss: 0.0060\n",
            "Epoch[90] Loss: 0.0078\n",
            "Epoch[90] Loss: 0.0056\n",
            "Epoch[90] Loss: 0.0051\n",
            "Epoch[90] Loss: 0.0079\n",
            "Epoch[90] Loss: 0.0092\n",
            "Epoch[90] Loss: 0.0060\n",
            "Epoch[90] Loss: 0.0055\n",
            "Epoch[90] Loss: 0.0096\n",
            "Epoch[90] Loss: 0.0068\n",
            "Epoch[90] Loss: 0.0068\n",
            "Epoch[90] Loss: 0.0055\n",
            "Epoch[90] Loss: 0.0124\n",
            "Training Results - Epoch: 90  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 90  Avg loss: 0.0072\n",
            "Epoch[91] Loss: 0.0074\n",
            "Epoch[91] Loss: 0.0076\n",
            "Epoch[91] Loss: 0.0061\n",
            "Epoch[91] Loss: 0.0080\n",
            "Epoch[91] Loss: 0.0071\n",
            "Epoch[91] Loss: 0.0068\n",
            "Epoch[91] Loss: 0.0065\n",
            "Epoch[91] Loss: 0.0058\n",
            "Epoch[91] Loss: 0.0076\n",
            "Epoch[91] Loss: 0.0088\n",
            "Epoch[91] Loss: 0.0071\n",
            "Epoch[91] Loss: 0.0054\n",
            "Epoch[91] Loss: 0.0058\n",
            "Epoch[91] Loss: 0.0064\n",
            "Epoch[91] Loss: 0.0073\n",
            "Epoch[91] Loss: 0.0067\n",
            "Epoch[91] Loss: 0.0059\n",
            "Epoch[91] Loss: 0.0055\n",
            "Epoch[91] Loss: 0.0065\n",
            "Training Results - Epoch: 91  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 91  Avg loss: 0.0085\n",
            "Epoch[92] Loss: 0.0064\n",
            "Epoch[92] Loss: 0.0054\n",
            "Epoch[92] Loss: 0.0069\n",
            "Epoch[92] Loss: 0.0094\n",
            "Epoch[92] Loss: 0.0078\n",
            "Epoch[92] Loss: 0.0093\n",
            "Epoch[92] Loss: 0.0089\n",
            "Epoch[92] Loss: 0.0064\n",
            "Epoch[92] Loss: 0.0052\n",
            "Epoch[92] Loss: 0.0044\n",
            "Epoch[92] Loss: 0.0072\n",
            "Epoch[92] Loss: 0.0061\n",
            "Epoch[92] Loss: 0.0046\n",
            "Epoch[92] Loss: 0.0069\n",
            "Epoch[92] Loss: 0.0115\n",
            "Epoch[92] Loss: 0.0073\n",
            "Epoch[92] Loss: 0.0053\n",
            "Epoch[92] Loss: 0.0081\n",
            "Epoch[92] Loss: 0.0064\n",
            "Training Results - Epoch: 92  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 92  Avg loss: 0.0078\n",
            "Epoch[93] Loss: 0.0061\n",
            "Epoch[93] Loss: 0.0062\n",
            "Epoch[93] Loss: 0.0061\n",
            "Epoch[93] Loss: 0.0059\n",
            "Epoch[93] Loss: 0.0064\n",
            "Epoch[93] Loss: 0.0081\n",
            "Epoch[93] Loss: 0.0068\n",
            "Epoch[93] Loss: 0.0070\n",
            "Epoch[93] Loss: 0.0073\n",
            "Epoch[93] Loss: 0.0071\n",
            "Epoch[93] Loss: 0.0055\n",
            "Epoch[93] Loss: 0.0075\n",
            "Epoch[93] Loss: 0.0052\n",
            "Epoch[93] Loss: 0.0069\n",
            "Epoch[93] Loss: 0.0052\n",
            "Epoch[93] Loss: 0.0046\n",
            "Epoch[93] Loss: 0.0067\n",
            "Epoch[93] Loss: 0.0078\n",
            "Epoch[93] Loss: 0.0054\n",
            "Training Results - Epoch: 93  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 93  Avg loss: 0.0078\n",
            "Epoch[94] Loss: 0.0076\n",
            "Epoch[94] Loss: 0.0051\n",
            "Epoch[94] Loss: 0.0086\n",
            "Epoch[94] Loss: 0.0051\n",
            "Epoch[94] Loss: 0.0063\n",
            "Epoch[94] Loss: 0.0071\n",
            "Epoch[94] Loss: 0.0069\n",
            "Epoch[94] Loss: 0.0054\n",
            "Epoch[94] Loss: 0.0084\n",
            "Epoch[94] Loss: 0.0070\n",
            "Epoch[94] Loss: 0.0055\n",
            "Epoch[94] Loss: 0.0083\n",
            "Epoch[94] Loss: 0.0098\n",
            "Epoch[94] Loss: 0.0047\n",
            "Epoch[94] Loss: 0.0079\n",
            "Epoch[94] Loss: 0.0062\n",
            "Epoch[94] Loss: 0.0088\n",
            "Epoch[94] Loss: 0.0070\n",
            "Epoch[94] Loss: 0.0064\n",
            "Training Results - Epoch: 94  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 94  Avg loss: 0.0077\n",
            "Epoch[95] Loss: 0.0077\n",
            "Epoch[95] Loss: 0.0071\n",
            "Epoch[95] Loss: 0.0067\n",
            "Epoch[95] Loss: 0.0046\n",
            "Epoch[95] Loss: 0.0067\n",
            "Epoch[95] Loss: 0.0060\n",
            "Epoch[95] Loss: 0.0062\n",
            "Epoch[95] Loss: 0.0075\n",
            "Epoch[95] Loss: 0.0091\n",
            "Epoch[95] Loss: 0.0061\n",
            "Epoch[95] Loss: 0.0092\n",
            "Epoch[95] Loss: 0.0042\n",
            "Epoch[95] Loss: 0.0071\n",
            "Epoch[95] Loss: 0.0080\n",
            "Epoch[95] Loss: 0.0056\n",
            "Epoch[95] Loss: 0.0061\n",
            "Epoch[95] Loss: 0.0070\n",
            "Epoch[95] Loss: 0.0073\n",
            "Epoch[95] Loss: 0.0106\n",
            "Training Results - Epoch: 95  Avg loss: 0.0062\n",
            "Validation Results - Epoch: 95  Avg loss: 0.0078\n",
            "Epoch[96] Loss: 0.0062\n",
            "Epoch[96] Loss: 0.0081\n",
            "Epoch[96] Loss: 0.0063\n",
            "Epoch[96] Loss: 0.0060\n",
            "Epoch[96] Loss: 0.0065\n",
            "Epoch[96] Loss: 0.0057\n",
            "Epoch[96] Loss: 0.0070\n",
            "Epoch[96] Loss: 0.0067\n",
            "Epoch[96] Loss: 0.0075\n",
            "Epoch[96] Loss: 0.0057\n",
            "Epoch[96] Loss: 0.0076\n",
            "Epoch[96] Loss: 0.0058\n",
            "Epoch[96] Loss: 0.0072\n",
            "Epoch[96] Loss: 0.0050\n",
            "Epoch[96] Loss: 0.0068\n",
            "Epoch[96] Loss: 0.0097\n",
            "Epoch[96] Loss: 0.0073\n",
            "Epoch[96] Loss: 0.0087\n",
            "Epoch[96] Loss: 0.0082\n",
            "Training Results - Epoch: 96  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 96  Avg loss: 0.0076\n",
            "Epoch[97] Loss: 0.0068\n",
            "Epoch[97] Loss: 0.0076\n",
            "Epoch[97] Loss: 0.0070\n",
            "Epoch[97] Loss: 0.0096\n",
            "Epoch[97] Loss: 0.0073\n",
            "Epoch[97] Loss: 0.0085\n",
            "Epoch[97] Loss: 0.0079\n",
            "Epoch[97] Loss: 0.0070\n",
            "Epoch[97] Loss: 0.0049\n",
            "Epoch[97] Loss: 0.0065\n",
            "Epoch[97] Loss: 0.0045\n",
            "Epoch[97] Loss: 0.0063\n",
            "Epoch[97] Loss: 0.0083\n",
            "Epoch[97] Loss: 0.0066\n",
            "Epoch[97] Loss: 0.0090\n",
            "Epoch[97] Loss: 0.0068\n",
            "Epoch[97] Loss: 0.0064\n",
            "Epoch[97] Loss: 0.0053\n",
            "Epoch[97] Loss: 0.0095\n",
            "Training Results - Epoch: 97  Avg loss: 0.0059\n",
            "Validation Results - Epoch: 97  Avg loss: 0.0082\n",
            "Epoch[98] Loss: 0.0053\n",
            "Epoch[98] Loss: 0.0050\n",
            "Epoch[98] Loss: 0.0081\n",
            "Epoch[98] Loss: 0.0053\n",
            "Epoch[98] Loss: 0.0085\n",
            "Epoch[98] Loss: 0.0061\n",
            "Epoch[98] Loss: 0.0117\n",
            "Epoch[98] Loss: 0.0051\n",
            "Epoch[98] Loss: 0.0066\n",
            "Epoch[98] Loss: 0.0057\n",
            "Epoch[98] Loss: 0.0073\n",
            "Epoch[98] Loss: 0.0070\n",
            "Epoch[98] Loss: 0.0072\n",
            "Epoch[98] Loss: 0.0072\n",
            "Epoch[98] Loss: 0.0059\n",
            "Epoch[98] Loss: 0.0081\n",
            "Epoch[98] Loss: 0.0060\n",
            "Epoch[98] Loss: 0.0083\n",
            "Epoch[98] Loss: 0.0048\n",
            "Training Results - Epoch: 98  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 98  Avg loss: 0.0074\n",
            "Epoch[99] Loss: 0.0088\n",
            "Epoch[99] Loss: 0.0096\n",
            "Epoch[99] Loss: 0.0090\n",
            "Epoch[99] Loss: 0.0070\n",
            "Epoch[99] Loss: 0.0066\n",
            "Epoch[99] Loss: 0.0060\n",
            "Epoch[99] Loss: 0.0069\n",
            "Epoch[99] Loss: 0.0054\n",
            "Epoch[99] Loss: 0.0050\n",
            "Epoch[99] Loss: 0.0082\n",
            "Epoch[99] Loss: 0.0065\n",
            "Epoch[99] Loss: 0.0081\n",
            "Epoch[99] Loss: 0.0081\n",
            "Epoch[99] Loss: 0.0057\n",
            "Epoch[99] Loss: 0.0063\n",
            "Epoch[99] Loss: 0.0062\n",
            "Epoch[99] Loss: 0.0067\n",
            "Epoch[99] Loss: 0.0064\n",
            "Epoch[99] Loss: 0.0049\n",
            "Training Results - Epoch: 99  Avg loss: 0.0061\n",
            "Validation Results - Epoch: 99  Avg loss: 0.0073\n",
            "Epoch[100] Loss: 0.0067\n",
            "Epoch[100] Loss: 0.0087\n",
            "Epoch[100] Loss: 0.0064\n",
            "Epoch[100] Loss: 0.0056\n",
            "Epoch[100] Loss: 0.0046\n",
            "Epoch[100] Loss: 0.0050\n",
            "Epoch[100] Loss: 0.0051\n",
            "Epoch[100] Loss: 0.0060\n",
            "Epoch[100] Loss: 0.0062\n",
            "Epoch[100] Loss: 0.0075\n",
            "Epoch[100] Loss: 0.0065\n",
            "Epoch[100] Loss: 0.0056\n",
            "Epoch[100] Loss: 0.0066\n",
            "Epoch[100] Loss: 0.0072\n",
            "Epoch[100] Loss: 0.0058\n",
            "Epoch[100] Loss: 0.0061\n",
            "Epoch[100] Loss: 0.0056\n",
            "Epoch[100] Loss: 0.0061\n",
            "Epoch[100] Loss: 0.0114\n",
            "Training Results - Epoch: 100  Avg loss: 0.0060\n",
            "Validation Results - Epoch: 100  Avg loss: 0.0081\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 1900\n",
              "\tepoch: 100\n",
              "\tepoch_length: 19\n",
              "\tmax_epochs: 100\n",
              "\toutput: 0.01137655321508646\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wcZqXtn4foCk",
        "outputId": "5626b048-ae5a-4baa-c4ee-3759f11f5174"
      },
      "source": [
        "testset = IrisDataset('CASIA1', transform=transform, train=False)\n",
        "# img0 = testset.load_image('/content/photo_2021-11-10_18-40-39 (1).jpg')\n",
        "# img0 = testset.load_image('/content/CASIA1/10/010_1_1.jpg')\n",
        "\n",
        "for i in range(10):\n",
        "    img0, label = testset[i]\n",
        "    outputs = model(torch.unsqueeze(img0.to('cuda'), 0))\n",
        "    x, y, r, x_o, y_o, r_o = outputs.flatten().tolist()\n",
        "    # print(outputs.flatten().tolist())\n",
        "    # print(label)\n",
        "    # label = torch.tensor(label)\n",
        "    # outputs = outputs.cpu().flatten()\n",
        "    # mse = torch.sqrt(((label - outputs)**2).mean())\n",
        "    # print(mse)\n",
        "    # mse = criterion(label, outputs)\n",
        "    # print(mse)\n",
        "\n",
        "    image = img0\n",
        "    image = image.numpy() * 256\n",
        "    # print(labels)\n",
        "    h, w = image.shape\n",
        "    image = cv2.circle(image, (int(x*w),int(y*w)), int(r*w), (255,), 2)\n",
        "    image = cv2.circle(image, (int(x_o*w),int(y_o*w)), int(r_o*w), (255,), 2)\n",
        "    cv2_imshow(image)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B81181D10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B8118BD10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B81181E90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B81181A90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B8118BDD0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B8118BDD0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B8118BD90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B81181D10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B81181A90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=64x64 at 0x7F5B81181B10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK6ff0f0LmqB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}